{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "523916ec",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Adam SenseAI - Multimodal LangChain Agent + Chroma DB\n",
    "\n",
    "- Ingest selected YouTube cooking videos\n",
    "- Transcribe with Whisper\n",
    "- Build / load Chroma DB\n",
    "- Persona-aligned RAG chain (Adam Ragusea style)\n",
    "- ReAct agent with tools + memory\n",
    "- Gradio UI with:\n",
    "    - Text questions + audio answers\n",
    "    - Voice questions + audio answers\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b81e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\langchain-demo\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c278630",
   "metadata": {},
   "source": [
    "**DEPENDANCIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c02269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.20 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (0.1.20)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (0.1.7)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (0.0.38)\n",
      "Requirement already satisfied: chromadb in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: youtube-transcript-api in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: yt-dlp in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (2025.11.12)\n",
      "Requirement already satisfied: openai in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (1.109.1)\n",
      "Requirement already satisfied: openai-whisper in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (20250625)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: gTTS in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (2.5.4)\n",
      "Requirement already satisfied: gradio in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (6.0.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langchain==0.1.20) (6.0.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langchain==0.1.20) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langchain==0.1.20) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langchain==0.1.20) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langchain==0.1.20) (0.1.53)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langchain==0.1.20) (0.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langchain==0.1.20) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langchain==0.1.20) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langchain==0.1.20) (2.12.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langchain==0.1.20) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langchain==0.1.20) (8.5.0)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (4.15.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (1.38.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (0.20.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (34.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (3.11.4)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from openai-whisper) (10.8.0)\n",
      "Requirement already satisfied: numba in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from openai-whisper) (0.62.1)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from openai-whisper) (2.9.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gTTS) (8.1.8)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (0.123.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==2.0.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (1.1.6)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (2.3.3)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (12.0.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (0.50.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio-client==2.0.1->gradio) (2025.10.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.20) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.20) (0.9.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (0.20.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.29.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.20) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.20) (1.0.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.59b0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.20) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.20) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.20) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from requests<3,>=2->langchain==0.1.20) (3.4.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.20) (3.2.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from numba->openai-whisper) (0.45.1)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from torch->openai-whisper) (3.6)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain==0.1.20) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.20) (1.1.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install \\\n",
    "    \"langchain==0.1.20\" \\\n",
    "    langchain-openai \\\n",
    "    langchain-community \\\n",
    "    chromadb \\\n",
    "    youtube-transcript-api \\\n",
    "    yt-dlp \\\n",
    "    openai \\\n",
    "    openai-whisper \\\n",
    "    tiktoken \\\n",
    "    pydub \\\n",
    "    gTTS \\\n",
    "    gradio \\\n",
    "    python-dotenv \\\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89500ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio>=4.0.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (6.0.2)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (4.11.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (0.123.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==2.0.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (2.0.1)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (1.1.6)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (3.0.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (3.11.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (2.3.3)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (12.0.0)\n",
      "Requirement already satisfied: pydantic<=2.12.4,>=2.11.10 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (2.12.4)\n",
      "Requirement already satisfied: pydub in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (6.0.3)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (0.50.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio>=4.0.0) (0.38.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from gradio-client==2.0.1->gradio>=4.0.0) (2025.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio>=4.0.0) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio>=4.0.0) (1.3.1)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from fastapi<1.0,>=0.115.2->gradio>=4.0.0) (0.0.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio>=4.0.0) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio>=4.0.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio>=4.0.0) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio>=4.0.0) (3.20.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio>=4.0.0) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio>=4.0.0) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio>=4.0.0) (4.67.1)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio>=4.0.0) (0.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio>=4.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio>=4.0.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio>=4.0.0) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio>=4.0.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio>=4.0.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio>=4.0.0) (0.4.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio>=4.0.0) (8.1.8)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio>=4.0.0) (14.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio>=4.0.0) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio>=4.0.0) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \"gradio>=4.0.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea6f6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langsmith>=0.1.60 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (0.1.147)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langsmith>=0.1.60) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langsmith>=0.1.60) (3.11.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langsmith>=0.1.60) (2.12.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langsmith>=0.1.60) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from langsmith>=0.1.60) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.60) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.60) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.60) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.60) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.60) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pydantic<3,>=1->langsmith>=0.1.60) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pydantic<3,>=1->langsmith>=0.1.60) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pydantic<3,>=1->langsmith>=0.1.60) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from pydantic<3,>=1->langsmith>=0.1.60) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.1.60) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith>=0.1.60) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.60) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install \"langsmith>=0.1.60\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4248e89d",
   "metadata": {},
   "source": [
    "**IMPORTS** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8342fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import tempfile\n",
    "import yt_dlp\n",
    "import whisper\n",
    "import gradio as gr\n",
    "\n",
    "from gtts import gTTS\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d2e96e",
   "metadata": {},
   "source": [
    "**PATHS & BASIC SETUP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de63f6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: c:\\Users\\User\\langchain-demo\n",
      "RAW_DIR: c:\\Users\\User\\langchain-demo\\data\\raw_transcripts\n",
      "AUDIO_DIR: c:\\Users\\User\\langchain-demo\\data\\audio\n",
      "CHROMA_DIR: c:\\Users\\User\\langchain-demo\\data\\chroma_db\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path.cwd()  # project root / current working directory\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw_transcripts\"\n",
    "AUDIO_DIR = DATA_DIR / \"audio\"\n",
    "CHROMA_DIR = DATA_DIR / \"chroma_db\"\n",
    "\n",
    "for d in [RAW_DIR, AUDIO_DIR, CHROMA_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"AUDIO_DIR:\", AUDIO_DIR)\n",
    "print(\"CHROMA_DIR:\", CHROMA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99126e5c",
   "metadata": {},
   "source": [
    "**KEYS: OpenAI_API_Key & LangChain_API_Key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85be3252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY set: True\n",
      "LANGCHAIN_API_KEY set: True\n",
      "LANGCHAIN_PROJECT: yt-rag-demo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Optional: sanity check\n",
    "print(\"OPENAI_API_KEY set:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "print(\"LANGCHAIN_API_KEY set:\", bool(os.getenv(\"LANGCHAIN_API_KEY\")))\n",
    "print(\"LANGCHAIN_PROJECT:\", os.getenv(\"LANGCHAIN_PROJECT\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51830c0",
   "metadata": {},
   "source": [
    "**Wisper Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b530051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Whisper once (can change model size if needed)\n",
    "whisper_model = whisper.load_model(\"small\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4033bea5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8b078f6",
   "metadata": {},
   "source": [
    "**1. YOUTUBE INGESTION + TRANSCRIPTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74382c1b",
   "metadata": {},
   "source": [
    "YouTube Video Ingestion Pipeline + Wisper\n",
    "✔ speech recognition\n",
    "✔ youtube retrieval\n",
    "✔ transcript processing\n",
    "✔ LangChain text preprocessing\n",
    "✔ RAG-ready docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b159a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(url: str) -> str:\n",
    "    \"\"\"Extract YouTube video id using yt-dlp.\"\"\"\n",
    "    ydl_opts = {\"quiet\": True, \"skip_download\": True}\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=False)\n",
    "    return info[\"id\"]\n",
    "\n",
    "\n",
    "\n",
    "def download_youtube_audio(url: str) -> Tuple[str, Path]:\n",
    "    \"\"\"\n",
    "    Download best audio from a YouTube URL as mp3.\n",
    "    Returns (video_id, audio_path).\n",
    "    \"\"\"\n",
    "    vid = extract_video_id(url)\n",
    "\n",
    "    # Let yt-dlp / ffmpeg decide extension, then we pick the mp3 afterwards\n",
    "    outtmpl = str(AUDIO_DIR / f\"{vid}.%(ext)s\")\n",
    "\n",
    "    ydl_opts = {\n",
    "        \"format\": \"bestaudio/best\",\n",
    "        \"outtmpl\": outtmpl,\n",
    "        \"quiet\": True,\n",
    "        \"postprocessors\": [\n",
    "            {\n",
    "                \"key\": \"FFmpegExtractAudio\",\n",
    "                \"preferredcodec\": \"mp3\",\n",
    "                \"preferredquality\": \"192\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "\n",
    "    # After postprocessing, we expect an mp3 with this video id\n",
    "    mp3_candidates = list(AUDIO_DIR.glob(f\"{vid}.mp3\"))\n",
    "    if not mp3_candidates:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Expected an mp3 file for video id {vid} in {AUDIO_DIR}, but none was found.\"\n",
    "        )\n",
    "\n",
    "    # If multiple, just take the first one\n",
    "    audio_path = mp3_candidates[0]\n",
    "    return vid, audio_path\n",
    "\n",
    "\n",
    "def transcribe_audio(path: Path) -> str:\n",
    "    \"\"\"Transcribe audio file with Whisper.\"\"\"\n",
    "    result = whisper_model.transcribe(str(path))\n",
    "    return result[\"text\"]\n",
    "\n",
    "\n",
    "\n",
    "def save_transcript(video_id: str, text: str) -> Path:\n",
    "    \"\"\"Save transcript into data/raw_transcripts/{video_id}.txt.\"\"\"\n",
    "    outpath = RAW_DIR / f\"{video_id}.txt\"\n",
    "    outpath.write_text(text, encoding=\"utf-8\")\n",
    "    return outpath\n",
    "\n",
    "\n",
    "\n",
    "def ingest_single_video(url: str) -> Tuple[str, Path]:\n",
    "    \"\"\"\n",
    "    Ingest a single YouTube video:\n",
    "        1) download audio\n",
    "        2) transcribe\n",
    "        3) save transcript\n",
    "    Returns (video_id, transcript_path).\n",
    "    \"\"\"\n",
    "    vid, audio_path = download_youtube_audio(url)\n",
    "    print(f\"[Ingest] Downloaded audio for video id: {vid}\")\n",
    "    transcript = transcribe_audio(audio_path)\n",
    "    print(f\"[Ingest] Transcribed audio for video id: {vid}\")\n",
    "    tpath = save_transcript(vid, transcript)\n",
    "    print(f\"[Ingest] Saved transcript to: {tpath}\")\n",
    "    return vid, tpath\n",
    "\n",
    "\n",
    "def ingest_selected_videos(urls: List[str]) -> List[Tuple[str, Path]]:\n",
    "    \"\"\"\n",
    "    Ingest all selected YouTube URLs.\n",
    "    This does NOT build the DB yet; that happens in a separate function.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            print(f\"\\n=== Processing URL: {url} ===\")\n",
    "            vid, tpath = ingest_single_video(url)\n",
    "            results.append((vid, tpath))\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not ingest {url}: {e}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5406c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test :\n",
    "# ingest_selected_videos([\"https://youtu.be/p8-_DJd1Ii8\"])  # Adam Ragusea video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1bbf1",
   "metadata": {},
   "source": [
    "**2. BUILD / LOAD CHROMA DB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10149666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcript_docs() -> List[Document]:\n",
    "    \"\"\"Load all transcript .txt files as LangChain Documents.\"\"\"\n",
    "    docs: List[Document] = []\n",
    "    for path in RAW_DIR.glob(\"*.txt\"):\n",
    "        text = path.read_text(encoding=\"utf-8\")\n",
    "        if text.strip():\n",
    "            docs.append(\n",
    "                Document(\n",
    "                    page_content=text,\n",
    "                    metadata={\"source\": path.name, \"video_id\": path.stem},\n",
    "                )\n",
    "            )\n",
    "    return docs\n",
    "\n",
    "\n",
    "\n",
    "def chunk_documents(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"Split documents into overlapping chunks for RAG.\"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=200,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    )\n",
    "    return splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "\n",
    "def build_chroma_db() -> Chroma:\n",
    "    \"\"\"\n",
    "    Build the Chroma vector DB from all transcripts in RAW_DIR.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Call this AFTER you've ingested the videos you want.\n",
    "      (i.e., after ingest_selected_videos([...]) )\n",
    "    \"\"\"\n",
    "    print(\"[DB] Loading transcripts from:\", RAW_DIR)\n",
    "    docs = load_transcript_docs()\n",
    "    print(f\"[DB] Loaded {len(docs)} document(s).\")\n",
    "\n",
    "    if not docs:\n",
    "        raise RuntimeError(\"No transcripts found. Ingest some YouTube videos first.\")\n",
    "\n",
    "    chunks = chunk_documents(docs)\n",
    "    print(f\"[DB] Created {len(chunks)} chunk(s).\")\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=str(CHROMA_DIR),\n",
    "        collection_name=\"adam_collection\",\n",
    "    )\n",
    "\n",
    "    vectordb.persist()\n",
    "    print(\"[DB] Chroma DB built & persisted at:\", CHROMA_DIR)\n",
    "    return vectordb\n",
    "\n",
    "\n",
    "def load_chroma_db() -> Chroma:\n",
    "    \"\"\"\n",
    "    Load an existing Chroma DB from disk.\n",
    "    Use this in a new session instead of rebuilding.\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectordb = Chroma(\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=str(CHROMA_DIR),\n",
    "        collection_name=\"adam_collection\",\n",
    "    )\n",
    "    print(\"[DB] Loaded Chroma DB from:\", CHROMA_DIR)\n",
    "    return vectordb\n",
    "\n",
    "def add_transcript_to_chroma(vectordb: Chroma, video_id: str) -> None:\n",
    "    \"\"\"\n",
    "    Incrementally add ONE transcript to an existing Chroma DB.\n",
    "\n",
    "    If the DB is empty or not yet built, you should call build_chroma_db()\n",
    "    instead of this function.\n",
    "    \"\"\"\n",
    "    path = RAW_DIR / f\"{video_id}.txt\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"No transcript file found for video id: {video_id}\")\n",
    "\n",
    "    text = path.read_text(encoding=\"utf-8\").strip()\n",
    "    if not text:\n",
    "        print(f\"[DB] Transcript for {video_id} is empty, skipping.\")\n",
    "        return\n",
    "\n",
    "    # Wrap in a Document and chunk just this transcript\n",
    "    doc = Document(\n",
    "        page_content=text,\n",
    "        metadata={\"source\": path.name, \"video_id\": video_id},\n",
    "    )\n",
    "    chunks = chunk_documents([doc])\n",
    "    print(f\"[DB] Adding {len(chunks)} chunk(s) for video {video_id} to Chroma...\")\n",
    "\n",
    "    vectordb.add_documents(chunks)\n",
    "    vectordb.persist()\n",
    "    print(\"[DB] Incremental update persisted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfc1279",
   "metadata": {},
   "source": [
    "**3. ADAM PERSONA & TOOLS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcd83d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADAM_PERSONA = \"\"\"\n",
    "You are an unofficial Adam Ragusea–style cooking assistant.\n",
    "\n",
    "Your highest priorities:\n",
    "1. FIRST, use the transcript for information whenever available.\n",
    "2. SECOND, express reasoning in Adam’s signature trade-off style (“on the one hand / on the other hand”) whenever the topic involves any kind of choice, preference, alternative technique, or difference in outcome.\n",
    "3. If the transcript does not address the question, you must explicitly state that and THEN give a brief, trade-off-based explanation from general cooking science.\n",
    "\n",
    "========================\n",
    "MANDATORY STRUCTURE\n",
    "========================\n",
    "\n",
    "1. **Transcript check section (always required):**\n",
    "   - Summarize exactly what the transcript says.\n",
    "   - If it doesn’t say anything, explicitly say:  \n",
    "     “Transcript check: the transcript does not address this topic.”\n",
    "\n",
    "2. **Trade-off reasoning section (always required when relevant):**\n",
    "   Use this pattern verbatim:\n",
    "   - \"On the one hand, ...\"\n",
    "   - \"On the other hand, ...\"\n",
    "\n",
    "   You must include **at least one** on-the-one-hand / on-the-other-hand contrast whenever the question involves:\n",
    "   - techniques (boiling vs steaming, pan types, salting methods)\n",
    "   - timing (salting early vs late)\n",
    "   - ingredients (butter vs oil, yogurt vs sour cream)\n",
    "   - any decision where Adam would discuss pros/cons\n",
    "\n",
    "3. **Final summary section:**\n",
    "   - Short, crisp, Adam-style conclusion.\n",
    "\n",
    "========================\n",
    "ADDITIONAL RULES\n",
    "========================\n",
    "- Never invent claims not supported by the transcript.\n",
    "- When using general cooking knowledge, keep it brief and clearly separated from transcript info.\n",
    "- Maintain Adam’s tone: calm, friendly, and science-minded.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4cc2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tools(vectordb: Chroma) -> List[Tool]:\n",
    "    \"\"\"\n",
    "    Create agent tools based on the current Chroma DB and transcript files.\n",
    "    \"\"\"\n",
    "\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "    def retrieve_tool(query: str) -> str:\n",
    "        \"\"\"\n",
    "        Use retriever to fetch relevant chunks.\n",
    "        \"\"\"\n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        return \"\\n\\n---\\n\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "    def get_transcript_tool(video_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Get full transcript text for a given video id (file name without .txt).\n",
    "        \"\"\"\n",
    "        path = RAW_DIR / f\"{video_id}.txt\"\n",
    "        if not path.exists():\n",
    "            return f\"No transcript found for video id: {video_id}\"\n",
    "        return path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"retrieve_docs\",\n",
    "            func=retrieve_tool,\n",
    "            description=(\n",
    "                \"Use this to look up relevant transcript chunks from the ingested YouTube cooking videos. \"\n",
    "                \"Best for answering questions about techniques, explanations, and steps.\"\n",
    "            ),\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"get_transcript\",\n",
    "            func=get_transcript_tool,\n",
    "            description=(\n",
    "                \"Use this to get the full transcript for a specific video id. \"\n",
    "                \"Video id = transcript file name without .txt\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    return tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c2d760",
   "metadata": {},
   "source": [
    "**4. RAG PROMPT + RAG CHAIN + AGENT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "808d6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADAM_RAG_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", ADAM_PERSONA),\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "You will answer the user's question using the provided transcript context.\n",
    "\n",
    "Rules:\n",
    "1. FIRST analyze whether the transcript answers the question.\n",
    "2. If the context is helpful, quote or summarize it.\n",
    "3. If the context is not helpful, say something like:\n",
    "   \"The transcript doesn't fully address this, but here's what I know...\"\n",
    "4. Then continue using cooking science and general knowledge.\n",
    "5. Use Adam-style trade-off reasoning.\n",
    "\n",
    "Transcript context:\n",
    "{context}\n",
    "        \"\"\",\n",
    "    ),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "def build_rag_and_agent(vdb: Chroma):\n",
    "    \"\"\"\n",
    "    Given a Chroma vectordb, create:\n",
    "      - RAG chain (rag_chain)\n",
    "      - ReAct agent with tools + memory (agent)\n",
    "    \"\"\"\n",
    "    retriever = vdb.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "    # Shared LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "    # ---- RAG chain ----\n",
    "    document_chain = create_stuff_documents_chain(\n",
    "        llm=llm,\n",
    "        prompt=ADAM_RAG_PROMPT,\n",
    "    )\n",
    "\n",
    "    rag_chain = create_retrieval_chain(\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain=document_chain,\n",
    "    )\n",
    "\n",
    "    # ---- Tools + memory for agent ----\n",
    "    tools = create_tools(vdb)\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        return_messages=True,\n",
    "    )\n",
    "\n",
    "    # IMPORTANT: include {tools} and {tool_names} in the prompt\n",
    "    react_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            ADAM_PERSONA\n",
    "            + \"\\n\\nYou have access to the following tools:\\n{tools}\\n\\n\"\n",
    "              \"When using them, refer to them by name from this list: {tool_names}.\"\n",
    "        ),\n",
    "        (\"system\", \"You can call tools when needed. Think step-by-step.\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ])\n",
    "\n",
    "    react_agent = create_react_agent(\n",
    "        llm=llm,\n",
    "        tools=tools,\n",
    "        prompt=react_prompt,\n",
    "    )\n",
    "\n",
    "    agent = AgentExecutor(\n",
    "        agent=react_agent,\n",
    "        tools=tools,\n",
    "        verbose=True,\n",
    "        memory=memory,\n",
    "    )\n",
    "\n",
    "    return rag_chain, agent\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f407b054",
   "metadata": {},
   "source": [
    "**5. MULTIMODAL HELPERS (TTS + audio QA)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cf93a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech_file(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert text to an MP3 file using gTTS and return file path.\n",
    "    Used for voice answers (multimodal output).\n",
    "    \"\"\"\n",
    "    if not text or not text.strip():\n",
    "        return \"\"\n",
    "\n",
    "    tmp_dir = Path(tempfile.gettempdir())\n",
    "    fname = tmp_dir / f\"chef_sense_{uuid.uuid4().hex}.mp3\"\n",
    "    tts = gTTS(text=text, lang=\"en\")\n",
    "    tts.save(str(fname))\n",
    "    return str(fname)\n",
    "\n",
    "\n",
    "def transcribe_user_audio(audio_path: Path) -> str:\n",
    "    \"\"\"Transcribe user audio question with Whisper.\"\"\"\n",
    "    return transcribe_audio(audio_path)\n",
    "\n",
    "\n",
    "def ask_text(rag_chain, question: str, with_voice: bool = False):\n",
    "    \"\"\"\n",
    "    Ask a text question through the persona-aligned RAG chain.\n",
    "    Returns (answer_text, optional_audio_path).\n",
    "    \"\"\"\n",
    "    result = rag_chain.invoke({\"input\": question})\n",
    "    answer = result.get(\"answer\", str(result))\n",
    "\n",
    "    if with_voice:\n",
    "        audio_path = text_to_speech_file(answer)\n",
    "        return answer, audio_path\n",
    "    else:\n",
    "        return answer, None\n",
    "\n",
    "\n",
    "def ask_audio(rag_chain, audio_file: Path, with_voice: bool = False):\n",
    "    \"\"\"\n",
    "    Audio question:\n",
    "      1) transcribe user audio\n",
    "      2) send text into RAG chain\n",
    "      3) optional TTS answer\n",
    "    \"\"\"\n",
    "    text = transcribe_user_audio(audio_file)\n",
    "    print(f\"[User audio transcribed as]: {text!r}\")\n",
    "    return ask_text(rag_chain, text, with_voice=with_voice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d891fb65",
   "metadata": {},
   "source": [
    "**6. INIT DB GRADIO CALLBACKS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0de76c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = None\n",
    "rag_chain = None\n",
    "agent = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b8a842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vectordb_and_chains():\n",
    "    \"\"\"\n",
    "    Try to load existing DB; if none + transcripts exist, build it.\n",
    "    \"\"\"\n",
    "    global vectordb, rag_chain, agent\n",
    "\n",
    "    try:\n",
    "        vectordb = load_chroma_db()\n",
    "    except Exception as e:\n",
    "        print(\"[Init] Could not load existing DB:\", e)\n",
    "        print(\"[Init] Trying to build a new DB from transcripts...\")\n",
    "        try:\n",
    "            vectordb = build_chroma_db()\n",
    "        except Exception as e2:\n",
    "            print(\"[Init] Could not build DB either:\", e2)\n",
    "            vectordb = None\n",
    "\n",
    "    if vectordb is not None:\n",
    "        rag_chain, agent = build_rag_and_agent(vectordb)\n",
    "    else:\n",
    "        rag_chain, agent = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b8affa",
   "metadata": {},
   "source": [
    "Gradio Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cb8c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import uuid\n",
    "from gtts import gTTS  # make sure: pip install gTTS\n",
    "\n",
    "# ========= Audio helpers =========\n",
    "\n",
    "AUDIO_OUT_DIR = Path(\"generated_audio\")\n",
    "AUDIO_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def _safe_audio_path(audio_path) -> str | None:\n",
    "    \"\"\"\n",
    "    Ensure an audio path is a real, existing file. Return str or None.\n",
    "    \"\"\"\n",
    "    if not audio_path:\n",
    "        return None\n",
    "\n",
    "    p = Path(audio_path)\n",
    "    if p.is_file():\n",
    "        return str(p)\n",
    "\n",
    "    # If ask_text returned something odd, try relative to our audio dir\n",
    "    alt = AUDIO_OUT_DIR / p.name\n",
    "    if alt.is_file():\n",
    "        return str(alt)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def _fallback_tts(text: str, prefix: str = \"fallback\") -> str | None:\n",
    "    \"\"\"\n",
    "    Fallback TTS: generate an MP3 from text using gTTS.\n",
    "    Returns the filepath or None if text is empty or TTS fails.\n",
    "    \"\"\"\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    out_path = AUDIO_OUT_DIR / f\"{prefix}_{uuid.uuid4().hex}.mp3\"\n",
    "    try:\n",
    "        tts = gTTS(text=text, lang=\"en\")\n",
    "        tts.save(str(out_path))\n",
    "        return str(out_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[FALLBACK TTS ERROR] {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def _ensure_audio_for_answer(answer: str, audio_path, prefix: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Make sure we have a valid audio file for the answer.\n",
    "    Prefer the path returned by ask_text; if it's missing/invalid,\n",
    "    generate a fallback TTS file.\n",
    "    \"\"\"\n",
    "    # 1) Try audio from ask_text\n",
    "    valid = _safe_audio_path(audio_path)\n",
    "    if valid:\n",
    "        return valid\n",
    "\n",
    "    # 2) Fallback TTS\n",
    "    return _fallback_tts(answer, prefix=prefix)\n",
    "\n",
    "\n",
    "# ========= History helpers (convert to messages format) =========\n",
    "\n",
    "def _ensure_messages_history(history):\n",
    "    \"\"\"\n",
    "    Gradio's Chatbot in your version expects a list of messages:\n",
    "      [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]\n",
    "\n",
    "    If we receive an old-style list of (user, bot) tuples, convert it.\n",
    "    \"\"\"\n",
    "    if history is None:\n",
    "        return []\n",
    "\n",
    "    if len(history) == 0:\n",
    "        return []\n",
    "\n",
    "    # If it's already messages (dicts with role/content), just return.\n",
    "    first = history[0]\n",
    "    if isinstance(first, dict) and \"role\" in first and \"content\" in first:\n",
    "        return history\n",
    "\n",
    "    # Otherwise assume list of (user, bot) pairs and convert.\n",
    "    messages = []\n",
    "    for item in history:\n",
    "        if isinstance(item, (list, tuple)) and len(item) == 2:\n",
    "            user_msg, bot_msg = item\n",
    "            if user_msg not in (None, \"\"):\n",
    "                messages.append({\"role\": \"user\", \"content\": str(user_msg)})\n",
    "            if bot_msg not in (None, \"\"):\n",
    "                messages.append({\"role\": \"assistant\", \"content\": str(bot_msg)})\n",
    "    return messages\n",
    "\n",
    "\n",
    "def _append_turn(history, user_text: str, bot_text: str):\n",
    "    \"\"\"\n",
    "    Append one user+assistant turn to a messages-style history.\n",
    "    \"\"\"\n",
    "    history = _ensure_messages_history(history)\n",
    "    history.append({\"role\": \"user\", \"content\": user_text})\n",
    "    history.append({\"role\": \"assistant\", \"content\": bot_text})\n",
    "    return history\n",
    "\n",
    "\n",
    "# ========= Your callbacks (updated for messages format) =========\n",
    "\n",
    "def ingest_video_callback(url: str):\n",
    "    \"\"\"Gradio callback to ingest a video and update DB + RAG.\"\"\"\n",
    "    global vectordb, rag_chain, agent\n",
    "\n",
    "    if not url or not url.strip():\n",
    "        return \" Please provide a YouTube URL.\"\n",
    "\n",
    "    try:\n",
    "        # 1) Ingest (download + transcribe + save .txt)\n",
    "        video_id, tpath = ingest_single_video(url)\n",
    "\n",
    "        # 2) Update / build vector DB\n",
    "        if vectordb is None:\n",
    "            print(\"[Ingest] No existing DB, building from scratch...\")\n",
    "            vectordb = build_chroma_db()\n",
    "        else:\n",
    "            add_transcript_to_chroma(vectordb, video_id)\n",
    "\n",
    "        # 3) Rebuild chains (RAG + agent) on the updated DB\n",
    "        rag_chain, agent = build_rag_and_agent(vectordb)\n",
    "\n",
    "        return f\"✅ Video '{video_id}' ingested and DB updated.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[INGEST ERROR] {e}\")\n",
    "        return f\"❌ Error ingesting video: {e}\"\n",
    "\n",
    "\n",
    "def chat_callback(message, history):\n",
    "    \"\"\"\n",
    "    Text chat callback.\n",
    "\n",
    "    In this Gradio version, Chatbot expects:\n",
    "      history: list of {\"role\": ..., \"content\": ...} messages.\n",
    "    \"\"\"\n",
    "    history = _ensure_messages_history(history)\n",
    "\n",
    "    if not message:\n",
    "        return \"\", history, None\n",
    "\n",
    "    if rag_chain is None:\n",
    "        bot_text = \"⚠️ No DB loaded. Ingest at least one video first.\"\n",
    "        history = _append_turn(history, message, bot_text)\n",
    "        return \"\", history, None\n",
    "\n",
    "    try:\n",
    "        # ask_text should return (answer_text, audio_path)\n",
    "        answer, audio_path = ask_text(rag_chain, message, with_voice=True)\n",
    "\n",
    "        # Ensure we have a valid audio file; fallback to TTS if needed\n",
    "        audio_path = _ensure_audio_for_answer(\n",
    "            answer=answer,\n",
    "            audio_path=audio_path,\n",
    "            prefix=\"textchat\",\n",
    "        )\n",
    "\n",
    "        history = _append_turn(history, message, answer)\n",
    "        return \"\", history, audio_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[CHAT CALLBACK ERROR] {e}\")\n",
    "        bot_text = f\"⚠️ Error while generating answer: {e}\"\n",
    "        history = _append_turn(history, message, bot_text)\n",
    "        return \"\", history, None\n",
    "\n",
    "\n",
    "def voice_question_callback(audio_file, history):\n",
    "    \"\"\"\n",
    "    Voice chat callback.\n",
    "\n",
    "    history: list of messages (dicts), same as text chat.\n",
    "    \"\"\"\n",
    "    history = _ensure_messages_history(history)\n",
    "\n",
    "    if audio_file is None:\n",
    "        return history, None\n",
    "\n",
    "    if rag_chain is None:\n",
    "        bot_text = \"⚠️ No DB loaded. Ingest at least one video first.\"\n",
    "        history = _append_turn(history, \"[Voice]\", bot_text)\n",
    "        return history, None\n",
    "\n",
    "    try:\n",
    "        audio_path = Path(audio_file)\n",
    "\n",
    "        # 1) Transcribe user audio\n",
    "        text = transcribe_user_audio(audio_path)\n",
    "        print(f\"[User audio transcribed as]: {text!r}\")\n",
    "\n",
    "        if not text.strip():\n",
    "            bot_text = \"Sorry, I couldn't understand that audio. Could you try again?\"\n",
    "            history = _append_turn(history, \"[Voice]\", bot_text)\n",
    "            audio_reply = _fallback_tts(bot_text, prefix=\"voicechat_error\")\n",
    "            return history, audio_reply\n",
    "\n",
    "        # 2) Ask RAG\n",
    "        answer, answer_audio_path = ask_text(rag_chain, text, with_voice=True)\n",
    "\n",
    "        # 3) Ensure audio exists (fallback if missing)\n",
    "        answer_audio_path = _ensure_audio_for_answer(\n",
    "            answer=answer,\n",
    "            audio_path=answer_audio_path,\n",
    "            prefix=\"voicechat\",\n",
    "        )\n",
    "\n",
    "        # 4) Append one turn\n",
    "        history = _append_turn(history, f\"[Voice] {text}\", answer)\n",
    "\n",
    "        return history, answer_audio_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[VOICE CALLBACK ERROR] {e}\")\n",
    "        bot_text = f\"Error handling audio: {e}\"\n",
    "        history = _append_turn(history, \"[Voice error]\", bot_text)\n",
    "        return history, None\n",
    "\n",
    "\n",
    "def clear_text_chat():\n",
    "    \"\"\"Reset the text chat: empty input, empty history, no audio.\"\"\"\n",
    "    # history as empty messages list is fine\n",
    "    return \"\", [], None  # msg, history, audio_out\n",
    "\n",
    "\n",
    "def clear_voice_chat():\n",
    "    \"\"\"Reset the voice chat: empty history, no audio.\"\"\"\n",
    "    return [], None      # history, voice_audio_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2ec686",
   "metadata": {},
   "source": [
    "**7. GRADIO UI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41fa064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# =============================\n",
    "# CUSTOM CSS FROM MOCK\n",
    "# =============================\n",
    "\n",
    "CUSTOM_CSS = \"\"\"\n",
    "@import url('https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@400;500;600;700&display=swap');\n",
    "\n",
    ":root {\n",
    "    /* Very light, muted olive-tinted background */\n",
    "    --rag-bg: #F2F4EE;          /* main background */\n",
    "    --rag-surface: #FFFFFF;     /* cards white */\n",
    "    --rag-border: #C1C9B1;      /* soft olive-grey border */\n",
    "\n",
    "    /* Muted dark olive typography */\n",
    "    --rag-text: #323A28;        /* main text: dark, slightly more saturated olive */\n",
    "    --rag-muted-text: #586347;  /* labels, hints: olive-grey */\n",
    "\n",
    "    /* SLIGHTLY MORE SATURATED OLIVE ACCENT */\n",
    "    --rag-accent: #6F7C58;      /* muted but richer olive */\n",
    "    --rag-accent-hover: #5B6646;\n",
    "\n",
    "    --rag-input-bg: #FFFFFF;\n",
    "    --rag-input-focus-bg: #E9EDE2;\n",
    "\n",
    "    --rag-radius-lg: 1rem;\n",
    "}\n",
    "\n",
    "/* Global */\n",
    "body, .gradio-container {\n",
    "    font-family: \"IBM Plex Sans\", -apple-system, BlinkMacSystemFont, \"Helvetica Neue\",\n",
    "                 system-ui, sans-serif;\n",
    "    color: var(--rag-text);\n",
    "    background: var(--rag-bg);\n",
    "}\n",
    "\n",
    "/* Center blocks on desktop */\n",
    ".gradio-container > .gr-blocks {\n",
    "    max-width: 1100px;\n",
    "    margin: 0 auto;\n",
    "}\n",
    "\n",
    "/* Background + padding */\n",
    ".gradio-container {\n",
    "    background: radial-gradient(circle at top left, #E3E6DB 0, #F2F4EE 40%, #F2F4EE 100%);\n",
    "    padding: 0 1rem 2rem 1rem;\n",
    "}\n",
    "\n",
    "/* Title */\n",
    "#app-title {\n",
    "    text-align: center;\n",
    "    font-size: 2.2rem;\n",
    "    font-weight: 700;\n",
    "    letter-spacing: 0.01em;\n",
    "    margin-top: 0.75rem;\n",
    "    margin-bottom: 0.35rem;\n",
    "    color: var(--rag-text);\n",
    "}\n",
    "\n",
    "/* Subtitle */\n",
    "#app-subtitle {\n",
    "    text-align: center;\n",
    "    font-size: 1rem;\n",
    "    color: var(--rag-muted-text);\n",
    "    margin-bottom: 1rem;\n",
    "}\n",
    "\n",
    "/* Disclaimer (same bg tone as page) */\n",
    ".disclaimer-box {\n",
    "    background-color: var(--rag-bg);\n",
    "    border: 1px solid var(--rag-border);\n",
    "    color: var(--rag-text);\n",
    "    padding: 0.85rem 1.1rem;\n",
    "    border-radius: 0.9rem;\n",
    "    font-size: 0.9rem;\n",
    "    margin-bottom: 1.25rem;\n",
    "}\n",
    "\n",
    "/* Cards */\n",
    ".section-card {\n",
    "    background: var(--rag-surface);\n",
    "    border-radius: var(--rag-radius-lg);\n",
    "    border: 1px solid var(--rag-border);\n",
    "    box-shadow: 0 10px 28px rgba(16, 20, 12, 0.08);\n",
    "    padding: 1.1rem 1.25rem;\n",
    "}\n",
    "\n",
    "/* Step header: circle + text */\n",
    ".step-header {\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    gap: 0.6rem;\n",
    "    margin-bottom: 0.5rem;\n",
    "}\n",
    "\n",
    ".step-circle {\n",
    "    width: 1.8rem;\n",
    "    height: 1.8rem;\n",
    "    border-radius: 9999px;\n",
    "    background: transparent;                 /* no fill */\n",
    "    border: 2px solid var(--rag-accent);    /* outline only */\n",
    "    color: var(--rag-accent);               /* olive-grey text */\n",
    "    display: inline-flex;\n",
    "    align-items: center;\n",
    "    justify-content: center;\n",
    "    font-size: 0.9rem;\n",
    "    font-weight: 600;\n",
    "}\n",
    "\n",
    ".step-title {\n",
    "    font-size: 1.05rem;\n",
    "    font-weight: 600;\n",
    "    color: var(--rag-text);\n",
    "}\n",
    "\n",
    "/* Chatbots */\n",
    ".section-card .wrap {\n",
    "    border-radius: 0.75rem;\n",
    "}\n",
    "\n",
    "/* BUTTONS: main = filled muted olive, secondary outlined lighter */\n",
    "\n",
    "button, .gr-button {\n",
    "    border-radius: 9999px !important;\n",
    "    font-weight: 600 !important;\n",
    "    border: 1px solid var(--rag-accent) !important;\n",
    "    transition: all 0.14s ease-out;\n",
    "    padding: 0.55rem 1.2rem !important;\n",
    "    font-size: 0.9rem !important;\n",
    "\n",
    "    background: var(--rag-accent) !important;   /* filled muted olive */\n",
    "    color: #FFFFFF !important;\n",
    "    box-shadow: 0 8px 18px rgba(40, 46, 34, 0.28);\n",
    "}\n",
    "\n",
    "button:hover, .gr-button:hover,\n",
    "button:focus-visible, .gr-button:focus-visible {\n",
    "    background: var(--rag-accent-hover) !important;\n",
    "    border-color: var(--rag-accent-hover) !important;\n",
    "    transform: translateY(-1px);\n",
    "    box-shadow: 0 10px 26px rgba(40, 46, 34, 0.36);\n",
    "}\n",
    "\n",
    "/* Secondary buttons: outline only */\n",
    ".secondary-btn {\n",
    "    background: transparent !important;\n",
    "    color: var(--rag-muted-text) !important;\n",
    "    border-color: var(--rag-border) !important;\n",
    "    box-shadow: none !important;\n",
    "}\n",
    ".secondary-btn:hover,\n",
    ".secondary-btn:focus-visible {\n",
    "    background: rgba(204, 209, 191, 0.25) !important;\n",
    "    transform: none;\n",
    "}\n",
    "\n",
    "/* Inputs */\n",
    "input[type=\"text\"],\n",
    "input[type=\"number\"],\n",
    "input[type=\"password\"],\n",
    "textarea,\n",
    ".gr-textbox,\n",
    ".gr-text-input {\n",
    "    background: var(--rag-input-bg) !important;\n",
    "    border-radius: 0.55rem !important;\n",
    "    border: 1px solid var(--rag-border) !important;\n",
    "    padding: 0.6rem 0.8rem !important;\n",
    "    color: var(--rag-text) !important;\n",
    "    transition: all 0.14s ease-out;\n",
    "    font-size: 0.95rem;\n",
    "}\n",
    "\n",
    "input:focus,\n",
    "textarea:focus,\n",
    ".gr-textbox:focus-within,\n",
    ".gr-text-input:focus-within {\n",
    "    outline: none !important;\n",
    "    background: var(--rag-input-focus-bg) !important;\n",
    "    border-color: var(--rag-accent) !important;\n",
    "    box-shadow: 0 0 0 1px rgba(61, 70, 52, 0.3);\n",
    "}\n",
    "\n",
    "/* Placeholder */\n",
    "::placeholder {\n",
    "    color: #6F7C58;  /* muted but more saturated olive */\n",
    "}\n",
    "\n",
    "/* Chatbot */\n",
    ".gr-chatbot, .gr-chatbot .wrap {\n",
    "    background: #F7F9F2 !important;\n",
    "    border-radius: 0.9rem !important;\n",
    "    border: 1px solid var(--rag-border) !important;\n",
    "    color: var(--rag-text) !important;\n",
    "}\n",
    "\n",
    "/* Audio */\n",
    ".gradio-container .gr-audio {\n",
    "    border-radius: 0.9rem !important;\n",
    "    border: 1px solid var(--rag-border) !important;\n",
    "    background: #F7F9F2 !important;\n",
    "}\n",
    "\n",
    "/* Labels */\n",
    "label, .wrap .label-wrap span, .gr-input-label {\n",
    "    font-size: 0.8rem !important;\n",
    "    font-weight: 600 !important;\n",
    "    text-transform: uppercase;\n",
    "    letter-spacing: 0.12em;\n",
    "    color: var(--rag-muted-text);\n",
    "}\n",
    "\n",
    "/* --------- MOBILE OPTIMIZATION --------- */\n",
    "@media (max-width: 768px) {\n",
    "    body, .gradio-container {\n",
    "        font-size: 15px;\n",
    "    }\n",
    "\n",
    "    .gradio-container > .gr-blocks {\n",
    "        max-width: 100%;\n",
    "        margin: 0;\n",
    "    }\n",
    "\n",
    "    .gradio-container .gr-row {\n",
    "        flex-direction: column !important;\n",
    "        gap: 0.75rem !important;\n",
    "    }\n",
    "\n",
    "    .section-card {\n",
    "        padding: 0.9rem 0.9rem;\n",
    "        box-shadow: 0 8px 22px rgba(16, 20, 12, 0.08);\n",
    "    }\n",
    "\n",
    "    #app-title {\n",
    "        font-size: 1.8rem;\n",
    "        margin-top: 0.75rem;\n",
    "    }\n",
    "\n",
    "    #app-subtitle {\n",
    "        font-size: 0.95rem;\n",
    "        margin-bottom: 0.9rem;\n",
    "    }\n",
    "\n",
    "    .disclaimer-box {\n",
    "        font-size: 0.85rem;\n",
    "        padding: 0.75rem 0.85rem;\n",
    "    }\n",
    "\n",
    "    .gr-chatbot {\n",
    "        height: 260px !important;\n",
    "    }\n",
    "\n",
    "    .gradio-container .gr-row .gr-button {\n",
    "        width: 100%;\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34fed0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# NEW UI USING YOUR REAL LOGIC\n",
    "# =============================\n",
    "\n",
    "def build_gradio_app():\n",
    "    with gr.Blocks(title=\"ChefSense AI\") as demo:\n",
    "        # Inject custom CSS\n",
    "        gr.HTML(f\"<style>{CUSTOM_CSS}</style>\")\n",
    "\n",
    "        # Title + subtitle\n",
    "        gr.Markdown(\"# ChefSense AI\", elem_id=\"app-title\")\n",
    "        gr.Markdown(\n",
    "            \"Adam Ragusea-style cooking Q&A with YouTube-powered RAG.\",\n",
    "            elem_id=\"app-subtitle\",\n",
    "        )\n",
    "\n",
    "        # Disclaimer\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "<div class=\"disclaimer-box\">\n",
    "<b>Disclaimer:</b> ChefSense AI is an experimental assistant. It may be inaccurate, incomplete, or unsafe.\n",
    "Always double-check cooking times, temperatures, and food-safety guidance, and use your own judgment.\n",
    "This project is not affiliated with or endorsed by Adam Ragusea or YouTube.\n",
    "</div>\n",
    "            \"\"\",\n",
    "        )\n",
    "\n",
    "        # Main row: Ingestion + Text chat\n",
    "        with gr.Row():\n",
    "            # Left: ingestion\n",
    "            with gr.Column(scale=1, min_width=320, elem_classes=\"section-card\"):\n",
    "                gr.Markdown(\n",
    "                    '<div class=\"step-header\">'\n",
    "                    '<span class=\"step-circle\">1</span>'\n",
    "                    '<span class=\"step-title\">Ingest a YouTube Video</span>'\n",
    "                    '</div>'\n",
    "                )\n",
    "                gr.Markdown(\n",
    "                    \"Paste a cooking video URL to build or update the transcript database.\"\n",
    "                )\n",
    "                yt_url = gr.Textbox(\n",
    "                    label=\"YouTube URL\",\n",
    "                    placeholder=\"https://www.youtube.com/watch?v=...\",\n",
    "                )\n",
    "                ingest_btn = gr.Button(\"Ingest & Update DB\")\n",
    "                ingest_status = gr.Textbox(\n",
    "                    label=\"Ingestion Status\",\n",
    "                    interactive=False,\n",
    "                    lines=4,\n",
    "                )\n",
    "                ingest_btn.click(\n",
    "                    fn=ingest_video_callback,\n",
    "                    inputs=yt_url,\n",
    "                    outputs=ingest_status,\n",
    "                )\n",
    "\n",
    "            # Right: text chat\n",
    "            with gr.Column(scale=2, elem_classes=\"section-card\"):\n",
    "                gr.Markdown(\n",
    "                    '<div class=\"step-header\">'\n",
    "                    '<span class=\"step-circle\">2</span>'\n",
    "                    '<span class=\"step-title\">Text Chat</span>'\n",
    "                    '</div>'\n",
    "                )\n",
    "                gr.Markdown(\n",
    "                    \"Ask detailed questions about ingested videos.\\n\"\n",
    "                    \"Answers come back in Adam-style text plus optional audio.\"\n",
    "                )\n",
    "\n",
    "                chatbot = gr.Chatbot(\n",
    "                    label=\"Text chat history\",\n",
    "                    height=350,\n",
    "                )\n",
    "                msg = gr.Textbox(\n",
    "                    label=\"Your question\",\n",
    "                    placeholder=\"E.g. Why does Adam toast the rice first in his risotto?\",\n",
    "                )\n",
    "                audio_out = gr.Audio(\n",
    "                    label=\"🔊 Bot's voice answer (text chat)\",\n",
    "                    type=\"filepath\",\n",
    "                    interactive=False,\n",
    "                )\n",
    "                with gr.Row():\n",
    "                    clear_btn = gr.Button(\"Clear chat\", elem_classes=\"secondary-btn\")\n",
    "                    send_btn = gr.Button(\"Send\")\n",
    "\n",
    "                msg.submit(\n",
    "                    fn=chat_callback,\n",
    "                    inputs=[msg, chatbot],\n",
    "                    outputs=[msg, chatbot, audio_out],\n",
    "                )\n",
    "                send_btn.click(\n",
    "                    fn=chat_callback,\n",
    "                    inputs=[msg, chatbot],\n",
    "                    outputs=[msg, chatbot, audio_out],\n",
    "                )\n",
    "\n",
    "                clear_btn.click(\n",
    "                    fn=clear_text_chat,\n",
    "                    inputs=[],\n",
    "                    outputs=[msg, chatbot, audio_out],\n",
    "                    queue=False,\n",
    "                )\n",
    "\n",
    "        # Voice Q&A section\n",
    "        gr.Markdown(\n",
    "            '<div class=\"step-header\">'\n",
    "            '<span class=\"step-circle\">3</span>'\n",
    "            '<span class=\"step-title\">Voice Q&A</span>'\n",
    "            '</div>'\n",
    "        )\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(elem_classes=\"section-card\"):\n",
    "                gr.Markdown(\n",
    "                    \"Ask your question via microphone and get an Adam-style spoken answer.\"\n",
    "                )\n",
    "\n",
    "                voice_chatbot = gr.Chatbot(\n",
    "                    label=\"Voice chat history\",\n",
    "                    height=320,\n",
    "                )\n",
    "                audio_in = gr.Audio(\n",
    "                    label=\"🎤 Record or upload your question\",\n",
    "                    sources=[\"microphone\", \"upload\"],\n",
    "                    type=\"filepath\",\n",
    "                )\n",
    "                voice_audio_out = gr.Audio(\n",
    "                    label=\"🔊 Bot's voice answer (voice chat)\",\n",
    "                    type=\"filepath\",\n",
    "                    interactive=False,\n",
    "                )\n",
    "                with gr.Row():\n",
    "                    clear_voice_btn = gr.Button(\n",
    "                        \"Clear voice chat\", elem_classes=\"secondary-btn\"\n",
    "                    )\n",
    "                    voice_btn = gr.Button(\"Send voice question\")\n",
    "\n",
    "                voice_btn.click(\n",
    "                    fn=voice_question_callback,\n",
    "                    inputs=[audio_in, voice_chatbot],\n",
    "                    outputs=[voice_chatbot, voice_audio_out],\n",
    "                )\n",
    "\n",
    "                clear_voice_btn.click(\n",
    "                    fn=clear_voice_chat,\n",
    "                    inputs=[],\n",
    "                    outputs=[voice_chatbot, voice_audio_out],\n",
    "                    queue=False,\n",
    "                )\n",
    "\n",
    "    return demo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36681ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf70c42c",
   "metadata": {},
   "source": [
    "**8. PRE-INGESTING VIDEOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94582998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] ntyBmviVs4M: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] ntyBmviVs4M: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping ntyBmviVs4M, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] ibgnYejxRww: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] ibgnYejxRww: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping ibgnYejxRww, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] WALpdDTyj8o: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] WALpdDTyj8o: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping WALpdDTyj8o, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] xudhMRXvJI0: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] xudhMRXvJI0: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping xudhMRXvJI0, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] TDUcQhOzO1Q: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] TDUcQhOzO1Q: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping TDUcQhOzO1Q, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] cHx67tiqDHM: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] cHx67tiqDHM: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping cHx67tiqDHM, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] XrVEScFvPIA: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] XrVEScFvPIA: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping XrVEScFvPIA, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] 1Oq6KfHTBNA: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] 1Oq6KfHTBNA: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping 1Oq6KfHTBNA, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] EoL5R_0h9xk: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] EoL5R_0h9xk: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping EoL5R_0h9xk, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] p53xab3c3tg: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] p53xab3c3tg: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping p53xab3c3tg, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] X8B5ZtKIlWY: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] X8B5ZtKIlWY: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping X8B5ZtKIlWY, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] bHE0lpFl8Ig: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] bHE0lpFl8Ig: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping bHE0lpFl8Ig, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] CS0mUDrywt4: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] CS0mUDrywt4: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping CS0mUDrywt4, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] aoU-Noh_JE8: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] aoU-Noh_JE8: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping aoU-Noh_JE8, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] xER7YhsZcQ0: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] xER7YhsZcQ0: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping xER7YhsZcQ0, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] lyVHjF4eXHE: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] lyVHjF4eXHE: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping lyVHjF4eXHE, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] Wy6kZm-lC4g: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] Wy6kZm-lC4g: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping Wy6kZm-lC4g, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] TK3GJ1msiK4: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] TK3GJ1msiK4: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping TK3GJ1msiK4, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] m6kcANnAJSo: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] m6kcANnAJSo: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping m6kcANnAJSo, transcript already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one. To silence this warning, you can use  --extractor-args \"youtube:player_client=default\"\n",
      "WARNING: [youtube] zogvMiPpQrs: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] zogvMiPpQrs: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init ingest] Skipping zogvMiPpQrs, transcript already exists.\n",
      "Newly ingested IDs: []\n"
     ]
    }
   ],
   "source": [
    "SELECTED_VIDEO_URLS = [\n",
    "    \"https://youtu.be/ntyBmviVs4M\",\n",
    "    \"https://youtu.be/ibgnYejxRww\",\n",
    "    \"https://youtu.be/WALpdDTyj8o\",\n",
    "    \"https://youtu.be/xudhMRXvJI0\",\n",
    "    \"https://youtu.be/TDUcQhOzO1Q\",\n",
    "    \"https://youtu.be/cHx67tiqDHM\",\n",
    "    \"https://youtu.be/XrVEScFvPIA\",\n",
    "    \"https://youtu.be/1Oq6KfHTBNA\",\n",
    "    \"https://youtu.be/EoL5R_0h9xk\",\n",
    "    \"https://youtu.be/p53xab3c3tg\",\n",
    "    \"https://youtu.be/X8B5ZtKIlWY\",\n",
    "    \"https://youtu.be/bHE0lpFl8Ig\",\n",
    "    \"https://youtu.be/CS0mUDrywt4\",\n",
    "    \"https://youtu.be/aoU-Noh_JE8\",\n",
    "    \"https://youtu.be/xER7YhsZcQ0\",\n",
    "    \"https://youtu.be/lyVHjF4eXHE\",\n",
    "    \"https://youtu.be/Wy6kZm-lC4g\",\n",
    "    \"https://youtu.be/TK3GJ1msiK4\",\n",
    "    \"https://youtu.be/m6kcANnAJSo\",\n",
    "    \"https://youtu.be/zogvMiPpQrs\",\n",
    "]\n",
    "\n",
    "\n",
    "def ingest_only_missing(urls):\n",
    "    \"\"\"Ingest only videos from `urls` that don't yet have a transcript file.\"\"\"\n",
    "    ingested = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            vid = extract_video_id(url)\n",
    "            transcript_path = RAW_DIR / f\"{vid}.txt\"\n",
    "            if transcript_path.exists():\n",
    "                print(f\"[Init ingest] Skipping {vid}, transcript already exists.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"[Init ingest] Ingesting {url} (id={vid})...\")\n",
    "            video_id, tpath = ingest_single_video(url)\n",
    "            ingested.append(video_id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Init ingest] ERROR ingesting {url}: {e}\")\n",
    "\n",
    "    return ingested\n",
    "\n",
    "\n",
    "# Run this cell whenever you add more URLs above\n",
    "new_ids = ingest_only_missing(SELECTED_VIDEO_URLS)\n",
    "print(\"Newly ingested IDs:\", new_ids)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f7928",
   "metadata": {},
   "source": [
    "Building Updated DB + RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7681ce6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Loading transcripts from: c:\\Users\\User\\langchain-demo\\data\\raw_transcripts\n",
      "[DB] Loaded 21 document(s).\n",
      "[DB] Created 389 chunk(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Chroma DB built & persisted at: c:\\Users\\User\\langchain-demo\\data\\chroma_db\n"
     ]
    }
   ],
   "source": [
    "# After that, we rebuild the DB & chains from all transcripts on disk:\n",
    "vectordb = build_chroma_db()\n",
    "rag_chain, agent = build_rag_and_agent(vectordb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3dc9b1",
   "metadata": {},
   "source": [
    "check DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d323b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Transcript files in RAW_DIR ===\n",
      " - 1Oq6KfHTBNA.txt\n",
      " - 2nhjTXUUx9g.txt\n",
      " - aoU-Noh_JE8.txt\n",
      " - bHE0lpFl8Ig.txt\n",
      " - cHx67tiqDHM.txt\n",
      " - CS0mUDrywt4.txt\n",
      " - EoL5R_0h9xk.txt\n",
      " - ibgnYejxRww.txt\n",
      " - lyVHjF4eXHE.txt\n",
      " - m6kcANnAJSo.txt\n",
      " - ntyBmviVs4M.txt\n",
      " - p53xab3c3tg.txt\n",
      " - TDUcQhOzO1Q.txt\n",
      " - TK3GJ1msiK4.txt\n",
      " - WALpdDTyj8o.txt\n",
      " - Wy6kZm-lC4g.txt\n",
      " - X8B5ZtKIlWY.txt\n",
      " - xER7YhsZcQ0.txt\n",
      " - XrVEScFvPIA.txt\n",
      " - xudhMRXvJI0.txt\n",
      " - zogvMiPpQrs.txt\n",
      "Total transcripts: 21\n",
      "Chroma collection name: adam_collection\n",
      "Number of embeddings/documents in collection: 6652\n"
     ]
    }
   ],
   "source": [
    "def list_transcript_files():\n",
    "    print(\"=== Transcript files in RAW_DIR ===\")\n",
    "    paths = sorted(RAW_DIR.glob(\"*.txt\"))\n",
    "    for p in paths:\n",
    "        print(\" -\", p.name)\n",
    "    print(f\"Total transcripts: {len(paths)}\")\n",
    "\n",
    "\n",
    "def list_chroma_stats(vdb=None):\n",
    "    global vectordb\n",
    "    if vdb is None:\n",
    "        vdb = vectordb\n",
    "    if vdb is None:\n",
    "        print(\"No vectordb loaded.\")\n",
    "        return\n",
    "\n",
    "    # This works with langchain_community Chroma wrapper\n",
    "    try:\n",
    "        collection = vdb._collection  # underlying chroma collection\n",
    "        count = collection.count()\n",
    "        print(f\"Chroma collection name: {collection.name}\")\n",
    "        print(f\"Number of embeddings/documents in collection: {count}\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not read Chroma stats:\", e)\n",
    "\n",
    "list_transcript_files()\n",
    "list_chroma_stats()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2248c80",
   "metadata": {},
   "source": [
    "**9. BUILD DB + RAG + TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96bcd2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Loading transcripts from: c:\\Users\\User\\langchain-demo\\data\\raw_transcripts\n",
      "[DB] Loaded 21 document(s).\n",
      "[DB] Created 389 chunk(s).\n",
      "[DB] Chroma DB built & persisted at: c:\\Users\\User\\langchain-demo\\data\\chroma_db\n",
      "Adam-Bot: Transcript check: the transcript does not address this topic.\n",
      "\n",
      "However, I can explain that searing steak at high heat is primarily about developing flavor and texture. On the one hand, high heat creates a Maillard reaction, which is responsible for the delicious browned crust that enhances the steak's flavor. On the other hand, if the heat is too high or the steak is not properly prepared, it can lead to burning or uneven cooking, which detracts from the overall quality. \n",
      "\n",
      "In summary, searing at high heat is essential for flavor but requires careful control to avoid burning.\n"
     ]
    }
   ],
   "source": [
    "# 2) Build DB & chains\n",
    "vectordb = build_chroma_db()\n",
    "rag_chain, agent = build_rag_and_agent(vectordb)\n",
    "\n",
    "# 3) Optional quick test\n",
    "answer, _ = ask_text(\n",
    "    rag_chain,\n",
    "    \"Why do we sear steak at high heat? Answer in 3-4 sentences.\",\n",
    "    with_voice=False,\n",
    ")\n",
    "print(\"Adam-Bot:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a185ddb",
   "metadata": {},
   "source": [
    "**10. EVALUATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb9264",
   "metadata": {},
   "source": [
    "10.1 Shared evaluation dataset (Adam Ragusea–style questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c34dce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation dataset tailored to Adam Ragusea–style content\n",
    "\n",
    "EVAL_DATA = [\n",
    "    # --- Video-related / transcript-aware questions ---\n",
    "    {\n",
    "        \"input\": \"In the risotto video, why does Adam stir so much? What’s the food science reason?\",\n",
    "        \"expected\": \"Mentions starch release from rice, creaminess development, Adam’s reasoning style, trade-offs (more stirring = creamier but more work).\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"In Adam’s fried chicken video, why does he rest the chicken before frying?\",\n",
    "        \"expected\": \"Mentions batter hydration, adhesion, crispiness, and practical trade-offs.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What was Adam’s reasoning for baking bacon instead of pan-frying it?\",\n",
    "        \"expected\": \"Should mention even cooking, less splatter, less attention required, and texture trade-offs.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"How does Adam approach seasoning a steak, according to the transcript?\",\n",
    "        \"expected\": \"Mentions timing, salt penetration, crust formation, or explicitly notes if the transcript doesn’t mention it.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"In the pasta water segment, what does Adam say about salting water?\",\n",
    "        \"expected\": \"Mentions flavor balance, seasoning trade-offs, or explicitly states if the transcript doesn’t cover it.\"\n",
    "    },\n",
    "\n",
    "    # --- Technique questions ---\n",
    "    {\n",
    "        \"input\": \"Why does Adam often recommend starting vegetables in a cold pan?\",\n",
    "        \"expected\": \"Mentions moisture retention, even heat, browning control, or similar trade-offs.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Why would someone choose to use a carbon steel pan instead of stainless steel?\",\n",
    "        \"expected\": \"Mentions thermal conductivity, seasoning, nonstick-like properties, responsiveness, pros and cons.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What’s Adam’s general take on nonstick pans for high heat cooking?\",\n",
    "        \"expected\": \"Mentions safety, coating breakdown, better alternatives, and nuance.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Why does Adam often rest meat after cooking?\",\n",
    "        \"expected\": \"Mentions juices redistributing, carryover cooking, texture, and trade-offs.\"\n",
    "    },\n",
    "\n",
    "    # --- Food science questions ---\n",
    "    {\n",
    "        \"input\": \"Why do Maillard reactions happen more intensely at high heat?\",\n",
    "        \"expected\": \"Mentions amino acids and sugars, dryness, temperature threshold (~150°C/300°F), and flavor development.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What’s the difference between browning and caramelization?\",\n",
    "        \"expected\": \"Browning = Maillard (proteins + sugars); caramelization = sugar alone; both make complex flavors.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What happens chemically when butter browns?\",\n",
    "        \"expected\": \"Mentions milk solids, Maillard reaction, nutty aroma, water evaporation, and temperature sensitivity.\"\n",
    "    },\n",
    "\n",
    "    # --- Substitution questions ---\n",
    "    {\n",
    "        \"input\": \"Can I use Greek yogurt instead of sour cream in a cake?\",\n",
    "        \"expected\": \"Mentions fat content, moisture adjustment, tartness differences, and trade-offs.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"If I don’t have buttermilk, what’s a good substitute?\",\n",
    "        \"expected\": \"Mentions milk + acid (lemon, vinegar) or yogurt + milk, and notes fat/acidity trade-offs.\"\n",
    "    },\n",
    "\n",
    "    # --- Food safety questions ---\n",
    "    {\n",
    "        \"input\": \"Is it safe to store cooked chicken in the fridge for five days?\",\n",
    "        \"expected\": \"Mentions 3–4 day guideline, increasing risk after that, and that smell alone isn’t a perfect safety test.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Is it okay to eat steak that’s a little gray inside?\",\n",
    "        \"expected\": \"Mentions oxidation vs spoilage, proper cooking temps, smell/texture caveats, and safety nuance.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Are runny eggs safe for children?\",\n",
    "        \"expected\": \"Mentions salmonella risk, that vulnerable groups (kids, pregnant, elderly, immunocompromised) should be more cautious.\"\n",
    "    },\n",
    "\n",
    "    # --- Adam-style trade-off reasoning tests ---\n",
    "    {\n",
    "        \"input\": \"What’s the trade-off between cooking steak in butter vs oil?\",\n",
    "        \"expected\": \"Mentions oil’s higher smoke point, butter’s flavor but burning, mixing both, and trade-offs.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Should I rinse rice before cooking it?\",\n",
    "        \"expected\": \"Mentions starch removal, fluffier rice vs keeping starch for creamy/sticky textures — framed as trade-offs.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Is it better to boil or steam vegetables?\",\n",
    "        \"expected\": \"Mentions nutrient retention, texture, flavor, and acknowledges it depends on priorities; not a one-size-fits-all rule.\"\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7900aee1",
   "metadata": {},
   "source": [
    "10.1 Manual evaluation with pandas + matrix view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f82379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper to call the  Chat-bot\n",
    "def answer_question(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Simple wrapper for evaluation: text in -> text out via your RAG chain.\n",
    "    \"\"\"\n",
    "    if rag_chain is None:\n",
    "        raise RuntimeError(\"rag_chain is None. Build DB and RAG chain first.\")\n",
    "    answer, _ = ask_text(rag_chain, query, with_voice=False)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30f41541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Asking: 'In the risotto video, why does Adam stir so much? What’s the food science reason?'\n",
      "[2] Asking: 'In Adam’s fried chicken video, why does he rest the chicken before frying?'\n",
      "[3] Asking: 'What was Adam’s reasoning for baking bacon instead of pan-frying it?'\n",
      "[4] Asking: 'How does Adam approach seasoning a steak, according to the transcript?'\n",
      "[5] Asking: 'In the pasta water segment, what does Adam say about salting water?'\n",
      "[6] Asking: 'Why does Adam often recommend starting vegetables in a cold pan?'\n",
      "[7] Asking: 'Why would someone choose to use a carbon steel pan instead of stainless steel?'\n",
      "[8] Asking: 'What’s Adam’s general take on nonstick pans for high heat cooking?'\n",
      "[9] Asking: 'Why does Adam often rest meat after cooking?'\n",
      "[10] Asking: 'Why do Maillard reactions happen more intensely at high heat?'\n",
      "[11] Asking: 'What’s the difference between browning and caramelization?'\n",
      "[12] Asking: 'What happens chemically when butter browns?'\n",
      "[13] Asking: 'Can I use Greek yogurt instead of sour cream in a cake?'\n",
      "[14] Asking: 'If I don’t have buttermilk, what’s a good substitute?'\n",
      "[15] Asking: 'Is it safe to store cooked chicken in the fridge for five days?'\n",
      "[16] Asking: 'Is it okay to eat steak that’s a little gray inside?'\n",
      "[17] Asking: 'Are runny eggs safe for children?'\n",
      "[18] Asking: 'What’s the trade-off between cooking steak in butter vs oil?'\n",
      "[19] Asking: 'Should I rinse rice before cooking it?'\n",
      "[20] Asking: 'Is it better to boil or steam vegetables?'\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_notes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_answer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "helpfulness_score",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "food_safety_score",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "style_score",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "comments",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "11cec2ca-05ff-4185-81f3-4f8fd6a8eabe",
       "rows": [
        [
         "0",
         "1",
         "In the risotto video, why does Adam stir so much? What’s the food science reason?",
         "Mentions starch release from rice, creaminess development, Adam’s reasoning style, trade-offs (more stirring = creamier but more work).",
         "**Transcript check section:**\nThe transcript mentions that Adam stirs the risotto a little for the same reason that you stir anything in a pan, but it does not provide a specific food science reason for why stirring is important in making risotto.\n\n**Trade-off reasoning section:**\nOn the one hand, stirring risotto helps to release the starches from the rice, which contributes to the creamy texture that is characteristic of a well-made risotto. This starch release is crucial because it creates that velvety mouthfeel that many people love. On the other hand, excessive stirring can lead to overcooking the rice or breaking the grains, which might result in a mushy texture rather than the desired al dente bite. So, while stirring is important for creaminess, it needs to be done with care to maintain the integrity of the rice.\n\n**Final summary section:**\nIn summary, Adam stirs the risotto to help release starches for creaminess, but he balances it to avoid overcooking the rice.",
         null,
         null,
         null,
         ""
        ],
        [
         "1",
         "2",
         "In Adam’s fried chicken video, why does he rest the chicken before frying?",
         "Mentions batter hydration, adhesion, crispiness, and practical trade-offs.",
         "Transcript check: the transcript does not address this topic.\n\nThe transcript doesn't provide specific information about why Adam rests the chicken before frying, but here's what I know about the general cooking science behind it. \n\nOn the one hand, resting the chicken allows the moisture to redistribute throughout the meat, which can help keep it juicy during frying. This is particularly important because if you fry chicken immediately after seasoning or marinating, the moisture can escape, leading to drier meat.\n\nOn the other hand, resting can also allow the surface of the chicken to dry out slightly, which can help achieve a better crust when frying. A drier surface can lead to a crispier texture, as moisture can hinder the frying process.\n\nIn summary, resting chicken before frying is a balancing act between ensuring juiciness and achieving a crispy exterior.",
         null,
         null,
         null,
         ""
        ],
        [
         "2",
         "3",
         "What was Adam’s reasoning for baking bacon instead of pan-frying it?",
         "Should mention even cooking, less splatter, less attention required, and texture trade-offs.",
         "Transcript check: the transcript does not address this topic.\n\nThe general reasoning for baking bacon instead of pan-frying it often involves considerations of convenience and even cooking. \n\nOn the one hand, baking bacon allows for more even cooking, as the heat surrounds the bacon on all sides, which can lead to a more consistent texture and crispiness. Additionally, you can cook larger batches at once on a baking sheet, making it more efficient if you're preparing food for a crowd.\n\nOn the other hand, pan-frying bacon can give you more control over the cooking process, allowing you to adjust the heat and monitor the bacon more closely. It can also result in a more flavorful, crispy edge due to the direct contact with the hot pan.\n\nIn summary, baking bacon is great for even cooking and efficiency, while pan-frying offers control and potentially more flavor.",
         null,
         null,
         null,
         ""
        ],
        [
         "3",
         "4",
         "How does Adam approach seasoning a steak, according to the transcript?",
         "Mentions timing, salt penetration, crust formation, or explicitly notes if the transcript doesn’t mention it.",
         "**Transcript check section:**\nAccording to the transcript, Adam approaches seasoning a steak by generally not salting it in advance. He prefers to salt the meat right before cooking, as he enjoys using finishing salt that adds a crunchy texture at the table. He mentions that when making steak with board sauce, there’s no need to salt the outside since he slices it thin and tosses it in a seasoned sauce. However, when cutting thicker pieces, he acknowledges that some seasoning penetrating the meat is not a huge priority for him, but it's not terrible either. He also likes to use both cooked and raw pepper on the steak.\n\n**Trade-off reasoning section:**\nOn the one hand, salting the steak in advance can enhance flavor by allowing the salt to penetrate the meat, which can lead to a more evenly seasoned steak. This method can also help with moisture retention if done correctly. On the other hand, salting right before cooking, as Adam prefers, allows for a crunchy finishing salt that adds texture and a burst of flavor at the table, which many find appealing. This approach might not provide the same depth of flavor throughout the meat, but it aligns with his preference for a more immediate seasoning experience.\n\n**Final summary section:**\nIn summary, Adam favors salting his steak just before cooking and prioritizes finishing salt for texture, while acknowledging that some seasoning penetration can be beneficial, especially with thicker cuts.",
         null,
         null,
         null,
         ""
        ],
        [
         "4",
         "5",
         "In the pasta water segment, what does Adam say about salting water?",
         "Mentions flavor balance, seasoning trade-offs, or explicitly states if the transcript doesn’t cover it.",
         "Transcript check: The transcript states that Adam fills up a large pot with water, adds \"some big pinches of salt,\" and turns the heat on high. However, it does not provide detailed reasoning or specific advice about salting water for pasta.\n\nTrade-off reasoning section: On the one hand, salting pasta water is crucial because it enhances the flavor of the pasta itself, allowing it to absorb some of that salt as it cooks. This can lead to a more flavorful final dish. On the other hand, if you add too much salt, it can overpower the dish, especially if other components (like sauces or cheeses) are already salty, which is something Adam seems to be considering with his lasagna.\n\nFinal summary section: Salting pasta water is essential for flavor, but balance is key to avoid overwhelming the dish.",
         null,
         null,
         null,
         ""
        ],
        [
         "5",
         "6",
         "Why does Adam often recommend starting vegetables in a cold pan?",
         "Mentions moisture retention, even heat, browning control, or similar trade-offs.",
         "Transcript check: the transcript does not address this topic.\n\nThe transcript doesn't provide specific information about starting vegetables in a cold pan, but here's what I know about the technique. \n\nOn the one hand, starting vegetables in a cold pan allows them to gradually release moisture as they heat up, which can lead to better caramelization and flavor development. This method can help prevent sticking and ensure even cooking, especially for delicate vegetables.\n\nOn the other hand, starting in a hot pan can give you immediate browning and a nice sear, which is great for achieving that desirable Maillard reaction quickly. However, this can also lead to uneven cooking or burning if the heat is too high or if the pan is overcrowded.\n\nIn summary, starting vegetables in a cold pan can enhance flavor and texture through gradual cooking, while a hot pan can provide quick browning but may risk uneven results.",
         null,
         null,
         null,
         ""
        ],
        [
         "6",
         "7",
         "Why would someone choose to use a carbon steel pan instead of stainless steel?",
         "Mentions thermal conductivity, seasoning, nonstick-like properties, responsiveness, pros and cons.",
         "Transcript check: the transcript does not address this topic.\n\nThe choice between a carbon steel pan and a stainless steel pan often comes down to specific cooking needs and preferences. \n\nOn the one hand, carbon steel pans are excellent for high-heat cooking and can develop a natural non-stick surface over time, which is great for tasks like searing meat or stir-frying. They also tend to be lighter than stainless steel pans, making them easier to handle. \n\nOn the other hand, stainless steel pans are generally more durable and resistant to rust and corrosion. They are easier to clean and maintain, as they don’t require seasoning like carbon steel does. Stainless steel also provides a more stable cooking surface for tasks that require precise temperature control.\n\nIn summary, if you prioritize high-heat cooking and developing a non-stick surface, carbon steel might be the way to go. But if you want durability and ease of maintenance, stainless steel is likely the better choice.",
         null,
         null,
         null,
         ""
        ],
        [
         "7",
         "8",
         "What’s Adam’s general take on nonstick pans for high heat cooking?",
         "Mentions safety, coating breakdown, better alternatives, and nuance.",
         "Transcript check: the transcript does not address this topic.\n\nThe general consensus in cooking science regarding nonstick pans is that they can be useful for high-heat cooking, but there are trade-offs to consider. \n\nOn the one hand, nonstick pans are designed to prevent food from sticking, which can make cooking and cleanup easier, especially for delicate items like eggs or pancakes. They can also allow for cooking with less fat, which some people prefer for health reasons.\n\nOn the other hand, many nonstick coatings can degrade at high temperatures, potentially releasing harmful fumes or causing the coating to flake off. This means that while you can use nonstick pans for some high-heat applications, you should be cautious about exceeding the manufacturer's recommended temperature limits.\n\nIn summary, nonstick pans have their advantages for ease of use, but they may not be the best choice for high-heat cooking due to potential safety concerns.",
         null,
         null,
         null,
         ""
        ],
        [
         "8",
         "9",
         "Why does Adam often rest meat after cooking?",
         "Mentions juices redistributing, carryover cooking, texture, and trade-offs.",
         "**Transcript check section:**\nThe transcript explains that resting meat allows the juices inside to become more viscous as they cool, which helps them cling to the meat when it's cut. Adam mentions that this process aids in the meat absorbing its own juices, which will spill out during cutting, resulting in a thicker layer of juice on the meat.\n\n**Trade-off reasoning section:**\nOn the one hand, resting meat can enhance the overall juiciness and flavor because the thicker, cooler juices cling better to the surface, making each bite more succulent. On the other hand, if you don't rest the meat, you can serve it immediately while it's still hot, which might be preferable for certain dishes where temperature is key, but you risk losing more juices during cutting.\n\n**Final summary section:**\nIn short, resting meat allows for better juice retention and flavor, making it a worthwhile step in the cooking process.",
         null,
         null,
         null,
         ""
        ],
        [
         "9",
         "10",
         "Why do Maillard reactions happen more intensely at high heat?",
         "Mentions amino acids and sugars, dryness, temperature threshold (~150°C/300°F), and flavor development.",
         "Transcript check: the transcript does not address this topic.\n\nThe Maillard reaction, which is responsible for the browning and flavor development in cooked foods, occurs more intensely at high heat because higher temperatures accelerate the chemical reactions between amino acids and reducing sugars. \n\nOn the one hand, at higher temperatures, these reactants can reach the activation energy needed for the Maillard reaction to occur more rapidly, leading to more pronounced browning and complex flavors. \n\nOn the other hand, if the heat is too high, it can lead to burning or the formation of undesirable flavors, as well as the risk of moisture loss, which can inhibit the reaction since water is a byproduct of the Maillard process. \n\nIn summary, while high heat can enhance the Maillard reaction and improve flavor, it needs to be balanced to avoid burning and ensure optimal results.",
         null,
         null,
         null,
         ""
        ],
        [
         "10",
         "11",
         "What’s the difference between browning and caramelization?",
         "Browning = Maillard (proteins + sugars); caramelization = sugar alone; both make complex flavors.",
         "Transcript check: the transcript does not address this topic.\n\nThe difference between browning and caramelization lies in the chemical processes and the outcomes. \n\nOn the one hand, browning refers to the Maillard reaction, which occurs when proteins and sugars react under heat, creating complex flavors and a brown color. This process happens at a wide range of temperatures and can occur with various foods, not just sugars.\n\nOn the other hand, caramelization specifically involves the oxidation of sugar when heated, resulting in a sweet, rich flavor and a deep brown color. This process requires higher temperatures and is primarily associated with sugar-based foods.\n\nIn summary, while both processes result in browning, caramelization is a specific type of browning that focuses on sugars, while the Maillard reaction involves a broader range of ingredients and flavors.",
         null,
         null,
         null,
         ""
        ],
        [
         "11",
         "12",
         "What happens chemically when butter browns?",
         "Mentions milk solids, Maillard reaction, nutty aroma, water evaporation, and temperature sensitivity.",
         "Transcript check: the transcript does not address this topic.\n\nThe browning of butter, often referred to as \"beurre noisette,\" involves a few key chemical reactions. On the one hand, the milk solids in butter begin to caramelize, which contributes to the nutty flavor and brown color. This is a result of the Maillard reaction, where amino acids and reducing sugars react under heat. On the other hand, the water content in butter evaporates, allowing the fat to reach higher temperatures, which enhances the browning process. \n\nIn summary, browning butter is a delightful transformation that adds depth of flavor to your dishes, thanks to the interplay of caramelization and the Maillard reaction.",
         null,
         null,
         null,
         ""
        ],
        [
         "12",
         "13",
         "Can I use Greek yogurt instead of sour cream in a cake?",
         "Mentions fat content, moisture adjustment, tartness differences, and trade-offs.",
         "Transcript check: the transcript does not address this topic.\n\nThe transcript doesn't provide specific information about substituting Greek yogurt for sour cream in a cake. However, here's what I know:\n\nOn the one hand, Greek yogurt is thicker and has a higher protein content than sour cream, which can contribute to a denser cake texture. It also has a tangy flavor that can enhance the overall taste of the cake. \n\nOn the other hand, sour cream has a slightly higher fat content, which can make cakes richer and moister. Additionally, the acidity of sour cream can react differently in baking, potentially affecting the leavening process.\n\nIn summary, both Greek yogurt and sour cream can work in a cake, but using Greek yogurt may yield a denser texture while sour cream can provide more moisture and richness.",
         null,
         null,
         null,
         ""
        ],
        [
         "13",
         "14",
         "If I don’t have buttermilk, what’s a good substitute?",
         "Mentions milk + acid (lemon, vinegar) or yogurt + milk, and notes fat/acidity trade-offs.",
         "Transcript check: the transcript does not address this topic.\n\nThe transcript doesn't provide specific information about buttermilk substitutes, but here's what I know: \n\nA common substitute for buttermilk is to mix regular milk with an acid, such as vinegar or lemon juice. For every cup of buttermilk needed, you can use one cup of milk and add one tablespoon of either vinegar or lemon juice, letting it sit for about five to ten minutes to thicken slightly.\n\nOn the one hand, using this method gives you a similar acidity and thickness to buttermilk, which can help with the leavening in recipes that rely on it. On the other hand, if you have yogurt on hand, you can also thin it with a little water to achieve a similar consistency and tanginess, but it may not be as liquid as buttermilk.\n\nIn summary, if you don't have buttermilk, mixing milk with vinegar or lemon juice is a solid option, or you can thin yogurt as an alternative.",
         null,
         null,
         null,
         ""
        ],
        [
         "14",
         "15",
         "Is it safe to store cooked chicken in the fridge for five days?",
         "Mentions 3–4 day guideline, increasing risk after that, and that smell alone isn’t a perfect safety test.",
         "Transcript check: the transcript does not address this topic.\n\nThe general guideline for storing cooked chicken is that it is safe to keep it in the fridge for about 3 to 4 days. On the one hand, if you store it properly in an airtight container, you might stretch it to 5 days without significant risk of spoilage. On the other hand, the longer you keep it, the more the quality may decline, and there’s an increased chance of bacterial growth, even if it looks and smells fine.\n\nIn summary, while you might be able to store cooked chicken for five days, it's generally safer to consume it within four days to ensure both safety and quality.",
         null,
         null,
         null,
         ""
        ],
        [
         "15",
         "16",
         "Is it okay to eat steak that’s a little gray inside?",
         "Mentions oxidation vs spoilage, proper cooking temps, smell/texture caveats, and safety nuance.",
         "Transcript check: the transcript does not address this topic.\n\nThe transcript doesn't provide specific information about the color of steak, but here's what I know about it. \n\nOn the one hand, a steak that is gray inside may indicate that it has been cooked to a higher temperature, which can mean it's fully safe to eat, as long as it has reached the appropriate internal temperature (at least 145°F for medium rare). On the other hand, if a steak is gray and lacks the characteristic pink color of a properly cooked steak, it might be overcooked, which can lead to a tougher texture and less flavor.\n\nIn general, the color of the meat can be influenced by factors like the cooking method and the cut of meat. So, while a gray steak can be safe to eat, it may not provide the best eating experience if it’s overcooked.\n\nIn summary, a little gray inside can be fine if the steak is cooked to the right temperature, but it may not be as enjoyable if it’s overdone.",
         null,
         null,
         null,
         ""
        ],
        [
         "16",
         "17",
         "Are runny eggs safe for children?",
         "Mentions salmonella risk, that vulnerable groups (kids, pregnant, elderly, immunocompromised) should be more cautious.",
         "Transcript check: the transcript does not address this topic.\n\nHowever, here's what I know: When it comes to runny eggs, there are some important safety considerations. On the one hand, runny eggs can be delicious and are often enjoyed for their creamy texture and rich flavor. Many people find them appealing in dishes like soft-boiled eggs or sunny-side-up eggs. On the other hand, there is a risk of salmonella, a bacteria that can be present in raw or undercooked eggs, which can be particularly harmful to young children, the elderly, and those with weakened immune systems.\n\nIn general, if you're considering serving runny eggs to children, it's advisable to use pasteurized eggs, which have been heat-treated to kill harmful bacteria without cooking the egg. This way, you can enjoy the texture and flavor of runny eggs while minimizing health risks.\n\nIn summary, while runny eggs can be safe if precautions are taken, it's essential to consider the potential risks and choose pasteurized eggs when serving them to children.",
         null,
         null,
         null,
         ""
        ],
        [
         "17",
         "18",
         "What’s the trade-off between cooking steak in butter vs oil?",
         "Mentions oil’s higher smoke point, butter’s flavor but burning, mixing both, and trade-offs.",
         "**Transcript check section:**\nThe transcript does not address this topic.\n\n**Trade-off reasoning section:**\nThe choice between cooking steak in butter versus oil involves several considerations. \n\nOn the one hand, butter adds a rich flavor and can enhance the overall taste of the steak, as it contains milk solids that can caramelize and create a delicious crust. However, butter has a lower smoke point (around 350°F or 175°C), which means it can burn more easily, especially at high temperatures.\n\nOn the other hand, oil, particularly oils like canola or avocado, has a higher smoke point (around 400°F to 520°F or 200°C to 270°C), making it more suitable for high-heat cooking methods without the risk of burning. This allows for a good sear on the steak without the risk of off-flavors from burnt butter.\n\n**Final summary section:**\nIn summary, if you prioritize flavor and richness, butter is a great choice, but be mindful of its lower smoke point. If you need higher heat tolerance and less risk of burning, oil might be the better option.",
         null,
         null,
         null,
         ""
        ],
        [
         "18",
         "19",
         "Should I rinse rice before cooking it?",
         "Mentions starch removal, fluffier rice vs keeping starch for creamy/sticky textures — framed as trade-offs.",
         "Transcript check: the transcript does not address this topic.\n\nThe general consensus on rinsing rice before cooking varies. On the one hand, rinsing rice can remove excess starch, which helps prevent it from becoming gummy and results in a fluffier texture. This is especially beneficial for long-grain varieties like basmati. On the other hand, some recipes, particularly for risotto, recommend not rinsing the rice, as the starch contributes to the creaminess of the dish. \n\nIn the context of risotto, which is what the transcript discusses, rinsing would not be advisable since you want that starch to help create the desired creamy consistency.\n\nIn summary, whether to rinse rice depends on the type of rice and the dish you're preparing, but for risotto, it's best to skip the rinse.",
         null,
         null,
         null,
         ""
        ],
        [
         "19",
         "20",
         "Is it better to boil or steam vegetables?",
         "Mentions nutrient retention, texture, flavor, and acknowledges it depends on priorities; not a one-size-fits-all rule.",
         "**Transcript check section:**\nThe transcript does not address this topic.\n\n**Trade-off reasoning section:**\nThe choice between boiling and steaming vegetables involves some important trade-offs. On the one hand, boiling can lead to a softer texture and quicker cooking time, making it easier to prepare certain vegetables, especially if you're looking to incorporate them into soups or stews. However, boiling can also cause significant nutrient loss, particularly water-soluble vitamins like vitamin C, as they leach into the cooking water.\n\nOn the other hand, steaming generally preserves more nutrients because the vegetables are not submerged in water. This method often results in a firmer texture and retains more of the vegetable's natural flavor. However, steaming can take a bit longer and may require specialized equipment, which might not be as convenient for everyone.\n\n**Final summary section:**\nIn summary, if nutrient retention and flavor are your priorities, steaming is likely the better choice. But if you're looking for speed and ease, boiling might be more suitable.",
         null,
         null,
         null,
         ""
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>expected_notes</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>helpfulness_score</th>\n",
       "      <th>food_safety_score</th>\n",
       "      <th>style_score</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>In the risotto video, why does Adam stir so mu...</td>\n",
       "      <td>Mentions starch release from rice, creaminess ...</td>\n",
       "      <td>**Transcript check section:**\\nThe transcript ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>In Adam’s fried chicken video, why does he res...</td>\n",
       "      <td>Mentions batter hydration, adhesion, crispines...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>What was Adam’s reasoning for baking bacon ins...</td>\n",
       "      <td>Should mention even cooking, less splatter, le...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>How does Adam approach seasoning a steak, acco...</td>\n",
       "      <td>Mentions timing, salt penetration, crust forma...</td>\n",
       "      <td>**Transcript check section:**\\nAccording to th...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>In the pasta water segment, what does Adam say...</td>\n",
       "      <td>Mentions flavor balance, seasoning trade-offs,...</td>\n",
       "      <td>Transcript check: The transcript states that A...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Why does Adam often recommend starting vegetab...</td>\n",
       "      <td>Mentions moisture retention, even heat, browni...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Why would someone choose to use a carbon steel...</td>\n",
       "      <td>Mentions thermal conductivity, seasoning, nons...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>What’s Adam’s general take on nonstick pans fo...</td>\n",
       "      <td>Mentions safety, coating breakdown, better alt...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Why does Adam often rest meat after cooking?</td>\n",
       "      <td>Mentions juices redistributing, carryover cook...</td>\n",
       "      <td>**Transcript check section:**\\nThe transcript ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Why do Maillard reactions happen more intensel...</td>\n",
       "      <td>Mentions amino acids and sugars, dryness, temp...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>What’s the difference between browning and car...</td>\n",
       "      <td>Browning = Maillard (proteins + sugars); caram...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>What happens chemically when butter browns?</td>\n",
       "      <td>Mentions milk solids, Maillard reaction, nutty...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Can I use Greek yogurt instead of sour cream i...</td>\n",
       "      <td>Mentions fat content, moisture adjustment, tar...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>If I don’t have buttermilk, what’s a good subs...</td>\n",
       "      <td>Mentions milk + acid (lemon, vinegar) or yogur...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Is it safe to store cooked chicken in the frid...</td>\n",
       "      <td>Mentions 3–4 day guideline, increasing risk af...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Is it okay to eat steak that’s a little gray i...</td>\n",
       "      <td>Mentions oxidation vs spoilage, proper cooking...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Are runny eggs safe for children?</td>\n",
       "      <td>Mentions salmonella risk, that vulnerable grou...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>What’s the trade-off between cooking steak in ...</td>\n",
       "      <td>Mentions oil’s higher smoke point, butter’s fl...</td>\n",
       "      <td>**Transcript check section:**\\nThe transcript ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Should I rinse rice before cooking it?</td>\n",
       "      <td>Mentions starch removal, fluffier rice vs keep...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Is it better to boil or steam vegetables?</td>\n",
       "      <td>Mentions nutrient retention, texture, flavor, ...</td>\n",
       "      <td>**Transcript check section:**\\nThe transcript ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           question  \\\n",
       "0    1  In the risotto video, why does Adam stir so mu...   \n",
       "1    2  In Adam’s fried chicken video, why does he res...   \n",
       "2    3  What was Adam’s reasoning for baking bacon ins...   \n",
       "3    4  How does Adam approach seasoning a steak, acco...   \n",
       "4    5  In the pasta water segment, what does Adam say...   \n",
       "5    6  Why does Adam often recommend starting vegetab...   \n",
       "6    7  Why would someone choose to use a carbon steel...   \n",
       "7    8  What’s Adam’s general take on nonstick pans fo...   \n",
       "8    9       Why does Adam often rest meat after cooking?   \n",
       "9   10  Why do Maillard reactions happen more intensel...   \n",
       "10  11  What’s the difference between browning and car...   \n",
       "11  12        What happens chemically when butter browns?   \n",
       "12  13  Can I use Greek yogurt instead of sour cream i...   \n",
       "13  14  If I don’t have buttermilk, what’s a good subs...   \n",
       "14  15  Is it safe to store cooked chicken in the frid...   \n",
       "15  16  Is it okay to eat steak that’s a little gray i...   \n",
       "16  17                  Are runny eggs safe for children?   \n",
       "17  18  What’s the trade-off between cooking steak in ...   \n",
       "18  19             Should I rinse rice before cooking it?   \n",
       "19  20          Is it better to boil or steam vegetables?   \n",
       "\n",
       "                                       expected_notes  \\\n",
       "0   Mentions starch release from rice, creaminess ...   \n",
       "1   Mentions batter hydration, adhesion, crispines...   \n",
       "2   Should mention even cooking, less splatter, le...   \n",
       "3   Mentions timing, salt penetration, crust forma...   \n",
       "4   Mentions flavor balance, seasoning trade-offs,...   \n",
       "5   Mentions moisture retention, even heat, browni...   \n",
       "6   Mentions thermal conductivity, seasoning, nons...   \n",
       "7   Mentions safety, coating breakdown, better alt...   \n",
       "8   Mentions juices redistributing, carryover cook...   \n",
       "9   Mentions amino acids and sugars, dryness, temp...   \n",
       "10  Browning = Maillard (proteins + sugars); caram...   \n",
       "11  Mentions milk solids, Maillard reaction, nutty...   \n",
       "12  Mentions fat content, moisture adjustment, tar...   \n",
       "13  Mentions milk + acid (lemon, vinegar) or yogur...   \n",
       "14  Mentions 3–4 day guideline, increasing risk af...   \n",
       "15  Mentions oxidation vs spoilage, proper cooking...   \n",
       "16  Mentions salmonella risk, that vulnerable grou...   \n",
       "17  Mentions oil’s higher smoke point, butter’s fl...   \n",
       "18  Mentions starch removal, fluffier rice vs keep...   \n",
       "19  Mentions nutrient retention, texture, flavor, ...   \n",
       "\n",
       "                                         model_answer helpfulness_score  \\\n",
       "0   **Transcript check section:**\\nThe transcript ...              None   \n",
       "1   Transcript check: the transcript does not addr...              None   \n",
       "2   Transcript check: the transcript does not addr...              None   \n",
       "3   **Transcript check section:**\\nAccording to th...              None   \n",
       "4   Transcript check: The transcript states that A...              None   \n",
       "5   Transcript check: the transcript does not addr...              None   \n",
       "6   Transcript check: the transcript does not addr...              None   \n",
       "7   Transcript check: the transcript does not addr...              None   \n",
       "8   **Transcript check section:**\\nThe transcript ...              None   \n",
       "9   Transcript check: the transcript does not addr...              None   \n",
       "10  Transcript check: the transcript does not addr...              None   \n",
       "11  Transcript check: the transcript does not addr...              None   \n",
       "12  Transcript check: the transcript does not addr...              None   \n",
       "13  Transcript check: the transcript does not addr...              None   \n",
       "14  Transcript check: the transcript does not addr...              None   \n",
       "15  Transcript check: the transcript does not addr...              None   \n",
       "16  Transcript check: the transcript does not addr...              None   \n",
       "17  **Transcript check section:**\\nThe transcript ...              None   \n",
       "18  Transcript check: the transcript does not addr...              None   \n",
       "19  **Transcript check section:**\\nThe transcript ...              None   \n",
       "\n",
       "   food_safety_score style_score comments  \n",
       "0               None        None           \n",
       "1               None        None           \n",
       "2               None        None           \n",
       "3               None        None           \n",
       "4               None        None           \n",
       "5               None        None           \n",
       "6               None        None           \n",
       "7               None        None           \n",
       "8               None        None           \n",
       "9               None        None           \n",
       "10              None        None           \n",
       "11              None        None           \n",
       "12              None        None           \n",
       "13              None        None           \n",
       "14              None        None           \n",
       "15              None        None           \n",
       "16              None        None           \n",
       "17              None        None           \n",
       "18              None        None           \n",
       "19              None        None           "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Run the dataset and collect answers\n",
    "import pandas as pd\n",
    "\n",
    "def run_manual_eval_dataset(eval_data):\n",
    "    rows = []\n",
    "    for i, row in enumerate(eval_data, start=1):\n",
    "        question = row[\"input\"]\n",
    "        expected = row.get(\"expected\", \"\")\n",
    "        print(f\"[{i}] Asking: {question!r}\")\n",
    "        model_answer = answer_question(question)\n",
    "        rows.append({\n",
    "            \"id\": i,\n",
    "            \"question\": question,\n",
    "            \"expected_notes\": expected,\n",
    "            \"model_answer\": model_answer,\n",
    "            # fields for you to fill in later (1–5 or similar)\n",
    "            \"helpfulness_score\": None,\n",
    "            \"food_safety_score\": None,\n",
    "            \"style_score\": None,   # Adam-style?\n",
    "            \"comments\": \"\",\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "manual_eval_df = run_manual_eval_dataset(EVAL_DATA)\n",
    "manual_eval_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "651f9439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved manual eval template to chef_sense_manual_eval_template.csv\n"
     ]
    }
   ],
   "source": [
    "# Export for manual annotation\n",
    "\n",
    "manual_eval_df.to_csv(\"chef_sense_manual_eval_template.csv\", index=False)\n",
    "print(\"Saved manual eval template to chef_sense_manual_eval_template.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20941d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_notes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_answer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "helpfulness_score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "food_safety_score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "style_score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "comments",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "67594621-0988-4044-82e4-5889a55a0cab",
       "rows": [
        [
         "0",
         "1",
         "In the risotto video, why does Adam stir so much? What’s the food science reason?",
         "Mentions starch release from rice, creaminess development, Adam’s reasoning style, trade-offs (more stirring = creamier but more work).",
         "**Transcript check section:**\nThe transcript states that Adam stirs the risotto a little for the same reason that you stir anything in a pan. However, it does not provide a specific food science reason for why stirring is important in making risotto.\n\n**Trade-off reasoning section:**\nOn the one hand, stirring risotto helps to release the starches from the rice, which contributes to the creamy texture that is characteristic of a well-made risotto. This is because the agitation encourages the rice to break down slightly, allowing the starches to gelatinize and thicken the cooking liquid. \n\nOn the other hand, excessive stirring can lead to overcooking the rice, making it mushy instead of al dente. Additionally, if you stir too much, you might not allow the rice to absorb the liquid properly, which can result in uneven cooking. \n\n**Final summary section:**\nIn essence, Adam stirs risotto to enhance its creaminess through starch release, but he balances this with the need to avoid overcooking the rice.",
         "4",
         "4",
         "5",
         null
        ],
        [
         "1",
         "2",
         "In Adam’s fried chicken video, why does he rest the chicken before frying?",
         "Mentions batter hydration, adhesion, crispiness, and practical trade-offs.",
         "Transcript check: the transcript does not address this topic.\n\nThe science behind resting chicken before frying generally involves allowing the meat to come closer to room temperature, which can help it cook more evenly. On the one hand, resting can help the chicken retain moisture during frying, leading to a juicier result. On the other hand, if you don't rest it, you might save time, but the chicken could cook unevenly, resulting in a drier texture in some parts.\n\nIn summary, resting chicken before frying can improve moisture retention and even cooking, while skipping this step might save time but could compromise the final texture.",
         "4",
         "4",
         "5",
         null
        ],
        [
         "2",
         "3",
         "What was Adam’s reasoning for baking bacon instead of pan-frying it?",
         "Should mention even cooking, less splatter, less attention required, and texture trade-offs.",
         "Transcript check: the transcript does not address this topic.\n\nThe general reasoning for baking bacon instead of pan-frying it is quite interesting. On the one hand, baking bacon allows for more even cooking and can render out more fat, resulting in a crispier texture without the need for constant flipping. It also frees up your stovetop for other tasks, which can be a big advantage when preparing a larger breakfast or meal. \n\nOn the other hand, pan-frying bacon gives you more control over the cooking process. You can adjust the heat more easily and watch for the exact level of crispiness you prefer. Additionally, the rendered fat in the pan can be used for cooking other ingredients, adding flavor to your dish.\n\nIn summary, baking bacon is a hands-off method that promotes even cooking, while pan-frying offers more control and versatility in the cooking process.",
         "4",
         "4",
         "5",
         null
        ],
        [
         "3",
         "4",
         "How does Adam approach seasoning a steak, according to the transcript?",
         "Mentions timing, salt penetration, crust formation, or explicitly notes if the transcript doesn’t mention it.",
         "**Transcript check section:**\nAccording to the transcript, Adam approaches seasoning a steak by generally not salting it in advance. He prefers to salt the meat right before cooking rather than letting it sit with salt for a long time. He emphasizes that he likes to use finishing salt, which adds a crunchy texture at the table. He also mentions that when making steak with board sauce, there's no need to salt the outside since he slices it thin and tosses it in a seasoned sauce. For thicker pieces of steak, he acknowledges that some seasoning penetrating the inside is acceptable, but it's not a huge priority for him. He also enjoys using both cooked and raw pepper on his steak.\n\n**Trade-off reasoning section:**\nOn the one hand, salting meat in advance can enhance flavor by allowing the salt to penetrate and tenderize the meat over time, which can be especially beneficial for thicker cuts. On the other hand, salting right before cooking, as Adam does, allows for a more controlled saltiness and preserves the texture of the meat, especially when he prefers a crunchy finishing salt. This approach can also prevent the steak from becoming overly salty if not monitored closely.\n\n**Final summary section:**\nIn summary, Adam favors salting steak just before cooking for better texture and a preference for finishing salt, while acknowledging that some seasoning can penetrate thicker cuts.",
         "5",
         "5",
         "5",
         null
        ],
        [
         "4",
         "5",
         "In the pasta water segment, what does Adam say about salting water?",
         "Mentions flavor balance, seasoning trade-offs, or explicitly states if the transcript doesn’t cover it.",
         "Transcript check: The transcript mentions that Adam fills up a large pot with water, adds \"big pinches of salt,\" and turns the heat on high. However, it does not provide specific details about the reasoning or technique behind salting the water.\n\nTrade-off reasoning section: \nOn the one hand, salting pasta water is essential because it enhances the flavor of the pasta itself, allowing it to absorb some of that saltiness while cooking. This can lead to a more flavorful dish overall. On the other hand, if you add too much salt, it can overpower the dish, especially if other components, like sauces or cheeses, are already salty. \n\nFinal summary section: In summary, salting pasta water is a crucial step for flavor, but it's important to balance it with the overall saltiness of the dish.",
         "5",
         "5",
         "5",
         null
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>expected_notes</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>helpfulness_score</th>\n",
       "      <th>food_safety_score</th>\n",
       "      <th>style_score</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>In the risotto video, why does Adam stir so mu...</td>\n",
       "      <td>Mentions starch release from rice, creaminess ...</td>\n",
       "      <td>**Transcript check section:**\\nThe transcript ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>In Adam’s fried chicken video, why does he res...</td>\n",
       "      <td>Mentions batter hydration, adhesion, crispines...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>What was Adam’s reasoning for baking bacon ins...</td>\n",
       "      <td>Should mention even cooking, less splatter, le...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>How does Adam approach seasoning a steak, acco...</td>\n",
       "      <td>Mentions timing, salt penetration, crust forma...</td>\n",
       "      <td>**Transcript check section:**\\nAccording to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>In the pasta water segment, what does Adam say...</td>\n",
       "      <td>Mentions flavor balance, seasoning trade-offs,...</td>\n",
       "      <td>Transcript check: The transcript mentions that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question  \\\n",
       "0   1  In the risotto video, why does Adam stir so mu...   \n",
       "1   2  In Adam’s fried chicken video, why does he res...   \n",
       "2   3  What was Adam’s reasoning for baking bacon ins...   \n",
       "3   4  How does Adam approach seasoning a steak, acco...   \n",
       "4   5  In the pasta water segment, what does Adam say...   \n",
       "\n",
       "                                      expected_notes  \\\n",
       "0  Mentions starch release from rice, creaminess ...   \n",
       "1  Mentions batter hydration, adhesion, crispines...   \n",
       "2  Should mention even cooking, less splatter, le...   \n",
       "3  Mentions timing, salt penetration, crust forma...   \n",
       "4  Mentions flavor balance, seasoning trade-offs,...   \n",
       "\n",
       "                                        model_answer  helpfulness_score  \\\n",
       "0  **Transcript check section:**\\nThe transcript ...                  4   \n",
       "1  Transcript check: the transcript does not addr...                  4   \n",
       "2  Transcript check: the transcript does not addr...                  4   \n",
       "3  **Transcript check section:**\\nAccording to th...                  5   \n",
       "4  Transcript check: The transcript mentions that...                  5   \n",
       "\n",
       "   food_safety_score  style_score  comments  \n",
       "0                  4            5       NaN  \n",
       "1                  4            5       NaN  \n",
       "2                  4            5       NaN  \n",
       "3                  5            5       NaN  \n",
       "4                  5            5       NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open that CSV in Excel/Sheets, fill in: helpfulness_score (e.g. 1–5); food_safety_score (1–5); style_score (1–5: how Adam-ish); comments\n",
    "# Then re-import:\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "annotated_df = pd.read_csv(\n",
    "    r\"C:\\Users\\User\\langchain-demo\\chef_sense_manual_evaluated.csv\",\n",
    "    encoding=\"cp1252\",\n",
    "    sep=\";\"          # tell Pandas it's semicolon-separated\n",
    ")\n",
    "\n",
    "annotated_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fb28070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build “matrix” views (crosstabs)\n",
    "def score_to_bucket(score):\n",
    "    if pd.isna(score):\n",
    "        return \"unrated\"\n",
    "    if score >= 4:\n",
    "        return \"good\"\n",
    "    if score >= 2:\n",
    "        return \"medium\"\n",
    "    return \"bad\"\n",
    "\n",
    "annotated_df[\"helpfulness_bucket\"] = annotated_df[\"helpfulness_score\"].apply(score_to_bucket)\n",
    "annotated_df[\"style_bucket\"] = annotated_df[\"style_score\"].apply(score_to_bucket)\n",
    "annotated_df[\"safety_bucket\"] = annotated_df[\"food_safety_score\"].apply(score_to_bucket)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c642ecad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Helpfulness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "good",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d6758073-68cc-4077-a119-4383b5168f39",
       "rows": [
        [
         "good",
         "20"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Adam-style</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Helpfulness</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Adam-style   good\n",
       "Helpfulness      \n",
       "good           20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helpfulness vs Adam-style matrix\n",
    "help_style_matrix = pd.crosstab(\n",
    "    annotated_df[\"helpfulness_bucket\"],\n",
    "    annotated_df[\"style_bucket\"],\n",
    "    rownames=[\"Helpfulness\"],\n",
    "    colnames=[\"Adam-style\"],\n",
    ")\n",
    "\n",
    "help_style_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "879e2d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Food safety",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "good",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3415da0e-b46e-4210-b301-a27a2f8d7822",
       "rows": [
        [
         "good",
         "18"
        ],
        [
         "medium",
         "2"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Helpfulness</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food safety</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Helpfulness  good\n",
       "Food safety      \n",
       "good           18\n",
       "medium          2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Food safety vs helpfulness matrix\n",
    "safety_help_matrix = pd.crosstab(\n",
    "    annotated_df[\"safety_bucket\"],\n",
    "    annotated_df[\"helpfulness_bucket\"],\n",
    "    rownames=[\"Food safety\"],\n",
    "    colnames=[\"Helpfulness\"],\n",
    ")\n",
    "\n",
    "safety_help_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "491194f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\langchain-demo\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae32a4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(help_style_matrix.values, aspect=\"auto\")\n",
    "plt.xticks(range(len(help_style_matrix.columns)), help_style_matrix.columns, rotation=45)\n",
    "plt.yticks(range(len(help_style_matrix.index)), help_style_matrix.index)\n",
    "plt.colorbar(label=\"Count\")\n",
    "plt.title(\"Helpfulness vs Adam-style Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b736d35",
   "metadata": {},
   "source": [
    "10.2. Langsmith Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2aa412e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated DF loaded with columns: ['id', 'question', 'expected_notes', 'model_answer', 'helpfulness_score', 'food_safety_score', 'style_score', 'comments']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_notes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_answer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "helpfulness_score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "food_safety_score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "style_score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "comments",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c5a5db33-f016-4d53-8e96-918150764cf7",
       "rows": [
        [
         "0",
         "1",
         "In the risotto video, why does Adam stir so much? What’s the food science reason?",
         "Mentions starch release from rice, creaminess development, Adam’s reasoning style, trade-offs (more stirring = creamier but more work).",
         "**Transcript check section:**\nThe transcript states that Adam stirs the risotto a little for the same reason that you stir anything in a pan. However, it does not provide a specific food science reason for why stirring is important in making risotto.\n\n**Trade-off reasoning section:**\nOn the one hand, stirring risotto helps to release the starches from the rice, which contributes to the creamy texture that is characteristic of a well-made risotto. This is because the agitation encourages the rice to break down slightly, allowing the starches to gelatinize and thicken the cooking liquid. \n\nOn the other hand, excessive stirring can lead to overcooking the rice, making it mushy instead of al dente. Additionally, if you stir too much, you might not allow the rice to absorb the liquid properly, which can result in uneven cooking. \n\n**Final summary section:**\nIn essence, Adam stirs risotto to enhance its creaminess through starch release, but he balances this with the need to avoid overcooking the rice.",
         "4",
         "4",
         "5",
         null
        ],
        [
         "1",
         "2",
         "In Adam’s fried chicken video, why does he rest the chicken before frying?",
         "Mentions batter hydration, adhesion, crispiness, and practical trade-offs.",
         "Transcript check: the transcript does not address this topic.\n\nThe science behind resting chicken before frying generally involves allowing the meat to come closer to room temperature, which can help it cook more evenly. On the one hand, resting can help the chicken retain moisture during frying, leading to a juicier result. On the other hand, if you don't rest it, you might save time, but the chicken could cook unevenly, resulting in a drier texture in some parts.\n\nIn summary, resting chicken before frying can improve moisture retention and even cooking, while skipping this step might save time but could compromise the final texture.",
         "4",
         "4",
         "5",
         null
        ],
        [
         "2",
         "3",
         "What was Adam’s reasoning for baking bacon instead of pan-frying it?",
         "Should mention even cooking, less splatter, less attention required, and texture trade-offs.",
         "Transcript check: the transcript does not address this topic.\n\nThe general reasoning for baking bacon instead of pan-frying it is quite interesting. On the one hand, baking bacon allows for more even cooking and can render out more fat, resulting in a crispier texture without the need for constant flipping. It also frees up your stovetop for other tasks, which can be a big advantage when preparing a larger breakfast or meal. \n\nOn the other hand, pan-frying bacon gives you more control over the cooking process. You can adjust the heat more easily and watch for the exact level of crispiness you prefer. Additionally, the rendered fat in the pan can be used for cooking other ingredients, adding flavor to your dish.\n\nIn summary, baking bacon is a hands-off method that promotes even cooking, while pan-frying offers more control and versatility in the cooking process.",
         "4",
         "4",
         "5",
         null
        ],
        [
         "3",
         "4",
         "How does Adam approach seasoning a steak, according to the transcript?",
         "Mentions timing, salt penetration, crust formation, or explicitly notes if the transcript doesn’t mention it.",
         "**Transcript check section:**\nAccording to the transcript, Adam approaches seasoning a steak by generally not salting it in advance. He prefers to salt the meat right before cooking rather than letting it sit with salt for a long time. He emphasizes that he likes to use finishing salt, which adds a crunchy texture at the table. He also mentions that when making steak with board sauce, there's no need to salt the outside since he slices it thin and tosses it in a seasoned sauce. For thicker pieces of steak, he acknowledges that some seasoning penetrating the inside is acceptable, but it's not a huge priority for him. He also enjoys using both cooked and raw pepper on his steak.\n\n**Trade-off reasoning section:**\nOn the one hand, salting meat in advance can enhance flavor by allowing the salt to penetrate and tenderize the meat over time, which can be especially beneficial for thicker cuts. On the other hand, salting right before cooking, as Adam does, allows for a more controlled saltiness and preserves the texture of the meat, especially when he prefers a crunchy finishing salt. This approach can also prevent the steak from becoming overly salty if not monitored closely.\n\n**Final summary section:**\nIn summary, Adam favors salting steak just before cooking for better texture and a preference for finishing salt, while acknowledging that some seasoning can penetrate thicker cuts.",
         "5",
         "5",
         "5",
         null
        ],
        [
         "4",
         "5",
         "In the pasta water segment, what does Adam say about salting water?",
         "Mentions flavor balance, seasoning trade-offs, or explicitly states if the transcript doesn’t cover it.",
         "Transcript check: The transcript mentions that Adam fills up a large pot with water, adds \"big pinches of salt,\" and turns the heat on high. However, it does not provide specific details about the reasoning or technique behind salting the water.\n\nTrade-off reasoning section: \nOn the one hand, salting pasta water is essential because it enhances the flavor of the pasta itself, allowing it to absorb some of that saltiness while cooking. This can lead to a more flavorful dish overall. On the other hand, if you add too much salt, it can overpower the dish, especially if other components, like sauces or cheeses, are already salty. \n\nFinal summary section: In summary, salting pasta water is a crucial step for flavor, but it's important to balance it with the overall saltiness of the dish.",
         "5",
         "5",
         "5",
         null
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>expected_notes</th>\n",
       "      <th>model_answer</th>\n",
       "      <th>helpfulness_score</th>\n",
       "      <th>food_safety_score</th>\n",
       "      <th>style_score</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>In the risotto video, why does Adam stir so mu...</td>\n",
       "      <td>Mentions starch release from rice, creaminess ...</td>\n",
       "      <td>**Transcript check section:**\\nThe transcript ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>In Adam’s fried chicken video, why does he res...</td>\n",
       "      <td>Mentions batter hydration, adhesion, crispines...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>What was Adam’s reasoning for baking bacon ins...</td>\n",
       "      <td>Should mention even cooking, less splatter, le...</td>\n",
       "      <td>Transcript check: the transcript does not addr...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>How does Adam approach seasoning a steak, acco...</td>\n",
       "      <td>Mentions timing, salt penetration, crust forma...</td>\n",
       "      <td>**Transcript check section:**\\nAccording to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>In the pasta water segment, what does Adam say...</td>\n",
       "      <td>Mentions flavor balance, seasoning trade-offs,...</td>\n",
       "      <td>Transcript check: The transcript mentions that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question  \\\n",
       "0   1  In the risotto video, why does Adam stir so mu...   \n",
       "1   2  In Adam’s fried chicken video, why does he res...   \n",
       "2   3  What was Adam’s reasoning for baking bacon ins...   \n",
       "3   4  How does Adam approach seasoning a steak, acco...   \n",
       "4   5  In the pasta water segment, what does Adam say...   \n",
       "\n",
       "                                      expected_notes  \\\n",
       "0  Mentions starch release from rice, creaminess ...   \n",
       "1  Mentions batter hydration, adhesion, crispines...   \n",
       "2  Should mention even cooking, less splatter, le...   \n",
       "3  Mentions timing, salt penetration, crust forma...   \n",
       "4  Mentions flavor balance, seasoning trade-offs,...   \n",
       "\n",
       "                                        model_answer  helpfulness_score  \\\n",
       "0  **Transcript check section:**\\nThe transcript ...                  4   \n",
       "1  Transcript check: the transcript does not addr...                  4   \n",
       "2  Transcript check: the transcript does not addr...                  4   \n",
       "3  **Transcript check section:**\\nAccording to th...                  5   \n",
       "4  Transcript check: The transcript mentions that...                  5   \n",
       "\n",
       "   food_safety_score  style_score  comments  \n",
       "0                  4            5       NaN  \n",
       "1                  4            5       NaN  \n",
       "2                  4            5       NaN  \n",
       "3                  5            5       NaN  \n",
       "4                  5            5       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith project: yt-rag-demo\n",
      "Using existing dataset 'chef-sense-manual-v1' (id=e1e9c17f-dbe4-4f38-bdf7-f883f292971e)\n",
      "View the evaluation results for experiment: 'chef-sense-criteria-eval-2f2788fe' at:\n",
      "https://smith.langchain.com/o/8f89f149-aa6b-4d90-a1fa-002eeb71f3bd/datasets/e1e9c17f-dbe4-4f38-bdf7-f883f292971e/compare?selectedSessions=f7c0e748-5339-41ca-a8e8-f6e0a872637d\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0a54b9a7d54f75896096914e38800e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: chef-sense-criteria-eval-2f2788fe\n",
      "Check this experiment in the LangSmith UI → Experiments tab.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langsmith import Client\n",
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "from langsmith.schemas import Run, Example\n",
    "\n",
    "\n",
    "# load annotated CSV from previous step\n",
    "annotated_df = pd.read_csv(\n",
    "    r\"C:\\Users\\User\\langchain-demo\\chef_sense_manual_evaluated.csv\",\n",
    "    encoding=\"cp1252\",\n",
    "    sep=\";\"          # tell Pandas it's semicolon-separated\n",
    ")\n",
    "\n",
    "annotated_df.head()\n",
    "\n",
    "print(\"Annotated DF loaded with columns:\", annotated_df.columns.tolist())\n",
    "display(annotated_df.head())\n",
    "\n",
    "\n",
    "# Build or load the Chroma DB\n",
    "rag_chain, agent = build_rag_and_agent(vectordb)\n",
    "\n",
    "# We'll refer to this as `chain` in the eval wrapper:\n",
    "chain = rag_chain\n",
    "\n",
    "\n",
    "# setting up LangSmith dataset\n",
    "client = Client()  # uses LANGCHAIN_API_KEY & LANGCHAIN_PROJECT\n",
    "DATASET_NAME = \"chef-sense-manual-v1\"\n",
    "\n",
    "print(\"LangSmith project:\", os.getenv(\"LANGCHAIN_PROJECT\", \"<not set>\"))\n",
    "\n",
    "# annotated_df is expected to have at least:\n",
    "#  - question\n",
    "#  - expected_notes\n",
    "#  - helpfulness_score\n",
    "#  - food_safety_score\n",
    "#  - style_score\n",
    "#  - comments\n",
    "\n",
    "if not client.has_dataset(dataset_name=DATASET_NAME):\n",
    "    print(f\"Creating dataset '{DATASET_NAME}' and uploading examples...\")\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=DATASET_NAME,\n",
    "        description=\"Manual eval set for Adam-style cooking bot\",\n",
    "    )\n",
    "\n",
    "    for _, row in annotated_df.iterrows():\n",
    "        inputs = {\n",
    "            \"question\": row[\"question\"],\n",
    "        }\n",
    "\n",
    "        outputs = {\n",
    "            \"expected_notes\": row.get(\"expected_notes\", \"\"),\n",
    "        }\n",
    "\n",
    "        metadata = {\n",
    "            \"helpfulness_score\": row.get(\"helpfulness_score\"),\n",
    "            \"food_safety_score\": row.get(\"food_safety_score\"),\n",
    "            \"style_score\": row.get(\"style_score\"),\n",
    "            \"comments\": row.get(\"comments\"),\n",
    "        }\n",
    "\n",
    "        client.create_example(\n",
    "            inputs=inputs,\n",
    "            outputs=outputs,\n",
    "            metadata=metadata,\n",
    "            dataset_id=dataset.id,\n",
    "        )\n",
    "else:\n",
    "    dataset = client.read_dataset(dataset_name=DATASET_NAME)\n",
    "    print(f\"Using existing dataset '{DATASET_NAME}' (id={dataset.id})\")\n",
    "\n",
    "\n",
    "# deifing the target function for evaluation\n",
    "def chef_bot_predict(inputs: dict) -> dict:\n",
    "    \"\"\"\n",
    "    inputs (from dataset): {\"question\": \"...\"}\n",
    "    chain expects: {\"input\": \"...\", \"chat_history\": [...]}\n",
    "    \"\"\"\n",
    "    question = inputs[\"question\"]\n",
    "\n",
    "    chain_input = {\n",
    "        \"input\": question,        # <-- what your retrieval chain expects\n",
    "        \"chat_history\": [],       # empty history for eval runs\n",
    "    }\n",
    "\n",
    "    answer = chain.invoke(chain_input)\n",
    "    return {\"output\": answer}\n",
    "\n",
    "\n",
    "\n",
    "# defining LLM and criteria for evaluation\n",
    "eval_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "criteria = {\n",
    "    \"helpfulness\": \"Is the answer detailed, practical, and useful for a home cook?\",\n",
    "    \"food_safety\": \"Does the answer avoid unsafe or misleading advice about food handling or cooking?\",\n",
    "    \"adam_style\": (\n",
    "        \"Does the answer sound like Adam Ragusea-style: calm, nerdy, \"\n",
    "        \"explaining trade-offs and food science instead of just giving steps?\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "def prepare_criteria_data(run: Run, example: Example):\n",
    "    \"\"\"\n",
    "    Map a LangSmith Run + Example into the strings\n",
    "    the criteria evaluator needs.\n",
    "    \"\"\"\n",
    "    outputs = run.outputs or {}\n",
    "    ex_inputs = example.inputs or {}\n",
    "    ex_outputs = example.outputs or {}\n",
    "\n",
    "    return {\n",
    "        \"prediction\": outputs.get(\"output\", \"\"),\n",
    "        \"reference\": ex_outputs.get(\"expected_notes\", \"\"),\n",
    "        \"input\": str(ex_inputs.get(\"question\", \"\")),\n",
    "    }\n",
    "\n",
    "criteria_evaluator = LangChainStringEvaluator(\n",
    "    \"labeled_criteria\",\n",
    "    config={\n",
    "        \"criteria\": criteria,\n",
    "        \"llm\": eval_llm,\n",
    "    },\n",
    "    prepare_data=prepare_criteria_data,\n",
    ")\n",
    "\n",
    "# Run the evaluation\n",
    "\n",
    "results = evaluate(\n",
    "    chef_bot_predict,              # target system\n",
    "    data=dataset,                  # LangSmith dataset object\n",
    "    evaluators=[criteria_evaluator],\n",
    "    experiment_prefix=\"chef-sense-criteria-eval\",\n",
    "    description=(\n",
    "        \"Evaluate Adam-style cooking bot on manual Q&A set with \"\n",
    "        \"helpfulness, food_safety, and Adam-style criteria.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Experiment name:\", results.experiment_name)\n",
    "print(\"Check this experiment in the LangSmith UI → Experiments tab.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b889d",
   "metadata": {},
   "source": [
    "**11. BUILD + LAUNCH APP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940b3262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Loaded Chroma DB from: c:\\Users\\User\\langchain-demo\\data\\chroma_db\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\fastapi\\applications.py\", line 1134, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\applications.py\", line 107, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\gradio\\brotli_middleware.py\", line 74, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 882, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 63, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\fastapi\\middleware\\asyncexitstack.py\", line 18, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 716, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 736, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 290, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\fastapi\\routing.py\", line 125, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\fastapi\\routing.py\", line 112, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\responses.py\", line 365, in __call__\n",
      "    await self._handle_simple(send, send_header_only, send_pathsend)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\responses.py\", line 396, in _handle_simple\n",
      "    await send({\"type\": \"http.response.body\", \"body\": chunk, \"more_body\": more_body})\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 39, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 39, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 161, in _send\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 544, in send\n",
      "    raise RuntimeError(\"Response content shorter than Content-Length\")\n",
      "RuntimeError: Response content shorter than Content-Length\n",
      "c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[User audio transcribed as]: \" How can I make Adam's crispy potatoes in the oven?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\fastapi\\applications.py\", line 1134, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\applications.py\", line 107, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\gradio\\brotli_middleware.py\", line 74, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 882, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 63, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\fastapi\\middleware\\asyncexitstack.py\", line 18, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 716, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 736, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 290, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\fastapi\\routing.py\", line 125, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\fastapi\\routing.py\", line 112, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\responses.py\", line 365, in __call__\n",
      "    await self._handle_simple(send, send_header_only, send_pathsend)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\responses.py\", line 396, in _handle_simple\n",
      "    await send({\"type\": \"http.response.body\", \"body\": chunk, \"more_body\": more_body})\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 39, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 39, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 161, in _send\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 544, in send\n",
      "    raise RuntimeError(\"Response content shorter than Content-Length\")\n",
      "RuntimeError: Response content shorter than Content-Length\n",
      "c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[User audio transcribed as]: \" Hey, can you recommend something for dinner with an egg dish according to Adam's style, please?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[User audio transcribed as]: \" What is Adam's Assassin's spaghetti?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[User audio transcribed as]: \" What is Adam's Assassin's Spaghetti?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[User audio transcribed as]: \" What is Adam's Assassin's Spaghetti?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\fastapi\\applications.py\", line 1134, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\applications.py\", line 107, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\gradio\\brotli_middleware.py\", line 74, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 882, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 63, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\fastapi\\middleware\\asyncexitstack.py\", line 18, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 716, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 736, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 290, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\fastapi\\routing.py\", line 125, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\fastapi\\routing.py\", line 112, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\responses.py\", line 365, in __call__\n",
      "    await self._handle_simple(send, send_header_only, send_pathsend)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\responses.py\", line 396, in _handle_simple\n",
      "    await send({\"type\": \"http.response.body\", \"body\": chunk, \"more_body\": more_body})\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 39, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 39, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 161, in _send\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 544, in send\n",
      "    raise RuntimeError(\"Response content shorter than Content-Length\")\n",
      "RuntimeError: Response content shorter than Content-Length\n",
      "c:\\Users\\User\\langchain-demo\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[User audio transcribed as]: ' Okay. What shall we eat for dinner tonight?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make sure DB + chains are ready before launching\n",
    "init_vectordb_and_chains()\n",
    "app = build_gradio_app()\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bafb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e307530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef8c263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de200a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
